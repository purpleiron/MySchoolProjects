{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mKK4Rd8vhPS"
      },
      "source": [
        "#  **ICT303 - Assignment 1**\n",
        "\n",
        "**Your name: <enter here your full name>**\n",
        "\n",
        "**Student ID: <enter here your student ID>**\n",
        "\n",
        "**Email: <enter here your email address>**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Description**\n",
        "\n",
        "We would like to develop, using Multilayer Perceptron (MLP), a computer program that takes images of handwritten text, finds the written characters in the image and displays the written characters.\n",
        "\n",
        "To achieve this, we will proceed in steps:\n",
        "\n",
        "1. Develop and train an MLP for the recognition of handwritten characters from images. In the first instance, the images are assumed to contain only one handwritten.\n",
        "2. Train and test the MLP, and evaluate its performance by using loss curves and proper accuracy/performance measures\n",
        "3. Improve the performance of the MLP by tuning its hyper parameters.\n",
        "4. Extend the program you developed to localize (detect) and recognize handwritten characters in an image that contains multiple handwritten characters.\n",
        "\n",
        "For this purpose, we will use the following dataset for training, validation and testing: https://www.kaggle.com/datasets/dhruvildave/english-handwritten-characters-dataset.\n",
        "\n",
        "You are required to justify every design choice. Justifications should be theoretical and validated with experiments.\n",
        "\n",
        "It is important that you start as earlier as possible. Coding is usually easy. However, training neural networks and tuning its hyper-parameters takes time."
      ],
      "metadata": {
        "id": "by2yigAYoub0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2. Marking Guide**##\n",
        "\n",
        "- The overal structure of the program - it should follow the structure we used so far in the labs **[30 Marks]**. This includes:\n",
        "  - A class that defines the network architecture that extends the class `nn.Module`. It should have a constructor method (`__init__()`) and a forward function (`forward()`)\n",
        "  - The Trainer class\n",
        "  - A main function\n",
        "\n",
        "- Training working and running on GPU **[10 marks]**\n",
        "\n",
        "- Curves for training loss and validation loss plotted and training stopped when the network starts to overfit (i.e., when the validation loss starts to increase). You must use TensorBoard to visualize curves and monitor performance **[10 marks]**\n",
        "\n",
        "- Testing code properly working. **[10 marks]**\n",
        "\n",
        "- Hyper parameters finetuned and the best ones selected. **[10 marks]**\n",
        "\n",
        "- Quality of the dicussions **[20 marks]**: did the student discuss various design choices, including the hyperparamters or any choices they made to improve the performance? Any design choice should be properly justified.\n",
        "\n",
        "- Extension to the localization of the characters **[10 marks]**"
      ],
      "metadata": {
        "id": "y9y_vBKmcS3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. What to submit**\n",
        "\n",
        "You need to upload to LMS the notebook as well as a folder that contains the .py files you created. All classes should be implemented in .py files. The notebook will sever as a documentation of your work as well as the codes that demonstrated the training, validation and testing of your MLP models that you created.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uPY9Ha_3qs68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing all dependencies:\n",
        "\n"
      ],
      "metadata": {
        "id": "HaYk9F4k728O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Dependencies\n",
        "!pip install GitPython  # Install GitPython if not already available\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "from git import Repo\n",
        "\n",
        "print(\"Step 1: Dependencies imported.\")"
      ],
      "metadata": {
        "id": "z0FTwzaq796X",
        "outputId": "c7c105a9-c3bf-42a6-9b9a-58d15ff5130f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.10/dist-packages (3.1.42)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython) (4.0.11)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython) (5.0.1)\n",
            "Step 1: Dependencies imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the dataset photos"
      ],
      "metadata": {
        "id": "qAX0eAUg8C2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Clone the GitHub Repository\n",
        "repo_url = 'https://github.com/purpleiron/MySchoolProjects.git'\n",
        "destination_dir = '/content/MySchoolProjects'  # Destination directory in Colab\n",
        "\n",
        "if not os.path.exists(destination_dir):\n",
        "    Repo.clone_from(repo_url, destination_dir)\n",
        "    print(f\"Repository cloned to {destination_dir}.\")\n",
        "else:\n",
        "    print(f\"Directory {destination_dir} already exists. Skipping clone.\")\n",
        "\n",
        "# Navigate to the cloned repository\n",
        "#%cd /content/MySchoolProjects\n",
        "!git checkout cab2a8f9917bd930dd0d35389b7561db7f11f169\n",
        "#print(\"Checked out to the specific commit.\")\n",
        "\n",
        "# Step 3: Unzip the Dataset\n",
        "dataset_dir = '/content/MySchoolProjects/Advanced AI & ML/Assignment1/Dataset'\n",
        "zip_path = os.path.join(dataset_dir, 'archive.zip')\n",
        "\n",
        "# Debug: List files in the dataset directory to verify the zip file's presence\n",
        "print(f\"Files in dataset directory ({dataset_dir}):\")\n",
        "!ls \"{dataset_dir}\"\n",
        "\n",
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dataset_dir)  # Extract all contents to the dataset directory\n",
        "print(\"Step 3: Dataset unzipped.\")\n",
        "\n",
        "# Debug: List the directories after extraction to verify contents\n",
        "print(\"Directories after extraction:\")\n",
        "!ls \"{dataset_dir}\"\n",
        "\n",
        "# Corrected Step 4: Count the Number of Images in the Correct Folder\n",
        "# Assuming the images are directly in the 'Img' directory after your previous message\n",
        "images_folder_path = os.path.join(dataset_dir, 'Img')  # Corrected to 'Img'\n",
        "image_files = glob.glob(f'{images_folder_path}/*.png', recursive=True)  # Assuming all images are .png\n",
        "\n",
        "# Output the number of images\n",
        "print(f\"Step 4: Number of images in the folder: {len(image_files)}\")\n"
      ],
      "metadata": {
        "id": "tduJjidx8IEB",
        "outputId": "52bc8c9b-abe0-47ac-d82a-b980adbe32af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory /content/MySchoolProjects already exists. Skipping clone.\n",
            "HEAD is now at cab2a8f added the assignment jupyter notebook?\n",
            "Files in dataset directory (/content/MySchoolProjects/Advanced AI & ML/Assignment1/Dataset):\n",
            "archive.zip  english.csv  Img  readme\n",
            "Step 3: Dataset unzipped.\n",
            "Directories after extraction:\n",
            "archive.zip  english.csv  Img  readme\n",
            "Step 4: Number of images in the folder: 3410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Preprocessing the images\n",
        "\n",
        "I took a look at the images and they are basically black and white, so I guess there will be no need for using the three rgb channels and I should just convert the images to grayscale. This will reduce the amount of inputs by 3. I will first resize all the images to 28x28 so that the processing time will be much faster and I can focus on the high level functions before changing the resolution of the images to see if that will help the model be more accurate.\n",
        "\n"
      ],
      "metadata": {
        "id": "l2E9F65EAO-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define your transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),  # Convert images to grayscale\n",
        "    transforms.Resize((28, 28)),  # Resize images to 28x28\n",
        "    transforms.ToTensor(),  # Convert images to tensor\n",
        "])\n",
        "\n",
        "# Path to the 'Img' directory containing your images\n",
        "dataset_path = '/content/MySchoolProjects/Advanced AI & ML/Assignment1/Dataset/Img'\n",
        "\n",
        "# Load your dataset applying the transformations\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "# Create a DataLoader to batch and shuffle your data\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Example: Iterate over your dataset and do something with the data\n",
        "for images, labels in data_loader:\n",
        "    # Here, images are your preprocessed tensors, and labels are the class labels\n",
        "    # You can now feed 'images' to your neural network model\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "5QBSwRyKKbCa",
        "outputId": "2db62a8e-ec8c-4d56-8b95-8f43d153fd80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Couldn't find any class folder in /content/MySchoolProjects/Advanced AI & ML/Assignment1/Dataset/Img.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-bdde04543236>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Load your dataset applying the transformations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Create a DataLoader to batch and shuffle your data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in /content/MySchoolProjects/Advanced AI & ML/Assignment1/Dataset/Img."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}