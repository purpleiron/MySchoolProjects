{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdDimpLi2_nI"
      },
      "source": [
        "# **ICT303 - Advanced Machine Learning and Artificial Intelligence**\n",
        "# **Lab 3 - Linear Neural Networks**\n",
        "\n",
        "The goal of this lab is to learn how to implement, from scratch, the linear regression that we covered in the lecture. While deep learning (and other) programming frameworks already provide ready-to-use implementations, implementing things from scratch is the only way to make sure that you\n",
        "- understand the theoretical concepts,\n",
        "- really know what you are doing,  \n",
        "- can use efficiently these tools,\n",
        "- understand their limitations, and\n",
        "- can extend and build on the top of them to solve complex problems.\n",
        "\n",
        "This week, we will first start with a naive approach that implements the analytical solution of the linear regression model and run it on synthetically-generated data. For this, we will introduce the class **SyntheticRegressionData**.\n",
        "\n",
        "We will then extend the implementation by introducing the classes **LinearRegression** and **Trainer**, which implement the standard machine learning pipeline. This will give you an idea of what is involved in the implementation of machine learning models.\n",
        "\n",
        "Finally, you will be required to create these classes in separate modules (not just on the notebook) so that you can easily reuse them later.\n",
        "\n",
        "This lab is adapted from: https://d2l.ai/chapter_linear-regression/linear-regression-scratch.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. A short summary of linear regression**\n",
        "\n",
        "Recall, from the lecture, that  regression is the problem of estimating the value of a variable (output) $y$ as a function of $d$ variables (input) $\\textbf{x} = (x_1, \\dots, x_d)^\\top$. When using linear regression, this function, which defines the relation between the input $\\textbf{x}$ and the output $y$, is linear. In other words:\n",
        "\n",
        "$$\n",
        "y = \\langle \\textbf{W}, \\textbf{x} \\rangle + b = \\textbf{W}^{\\top} \\textbf{x} + b = \\sum_{i=1}^{d}w_ix_i + b,\n",
        "$$\n",
        "\n",
        "where\n",
        "- $\\textbf{W}$ is a column vector (thus $\\textbf{W}^\\top$ is a row vector), i.e., $\\textbf{W} = (w_1, \\cdots, w_d)^\\top$.\n",
        "- $b$ is a scalar and is called a bias.\n",
        "\n",
        "We can also write $\\textbf{x} = (x_1, \\dots, x_d, 1)^\\top$ and $\\textbf{W} = (w_1, \\cdots, w_d, b)^\\top$ so that the equation above becomes:\n",
        "$$\n",
        "y = \\langle \\textbf{W}, \\textbf{x} \\rangle = \\langle \\textbf{x} , \\textbf{W}\\rangle = \\textbf{W}^{\\top} \\textbf{x} = \\textbf{x}^{\\top} \\textbf{W}.\n",
        "$$\n",
        "\n",
        "$(w_1, \\cdots, w_d)$ and $b$ are called **parameters** of the model. The goal of the  training process is to find the right values of $(w_1, \\cdots, w_d)$ and $b$ from some training data (sometimes also called exemplars).\n",
        "\n",
        "Suppose that we have the following training data:\n",
        "-  $n$ input samples $\\textbf{x}^1, \\dots, \\textbf{x}^n$ stacked into a matrix $\\textbf{X}$ (the $i-$th column of the matrix $\\textbf{X}$ is actually the column vector $\\textbf{x}^i$).\n",
        "- For each sample $\\textbf{x}^i$, we have its desired output $y^i$. Let's put all the $y^i$'s into one column vector $\\textbf{y}$.\n",
        "\n",
        "We have seen during the lecture that the best values of the parameters $(w_1, \\cdots, w_d)$  and $b$ are those that minimize the following **loss function**:\n",
        "\n",
        "$$\n",
        "\\mathcal{l}(\\textbf{X}, \\textbf{y}, \\textbf{W}) = \\frac{1}{n}\\|\\textbf{y} - (\\textbf{W}^\\top \\textbf{X}) \\|^2.\n",
        "$$\n",
        "\n",
        "For further details, please refer to the lecture slides and the lecture recording."
      ],
      "metadata": {
        "id": "RNeECLiQOUgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Generating synthetic data**\n",
        "\n",
        "Machine learning is all about data. The data usually comes from practical problems. However, when developing machine learning models, we usually rely on synthetic data because:\n",
        "- They are easy to generate, by just writing some code\n",
        "- We know the input, the output, and  the process that generated them. Thus, we can easily evaluate whether our machine learning model works the way it is intended to.\n",
        "\n",
        "In the case of linear regression, we will need training data in the form of pairs $(\\textbf{x}^i, y^i)$ where $\\textbf{x}^i$ is the input and $y^i$ its corresponding output (called also label). In this example, let's start with a simple case where $\\textbf{x}^i$ is a scalar (i.e., just one value).\n",
        "\n",
        "Let's simulate $1000$ data points (i.e., $n=1000$). We generate each $\\textbf{x}^i$ randomly from a normal (Gaussian) distribution with mean $0$ and standard deviation $\\sigma = 0.01$ (any other values are also fine). Then, its corresponding output $y^i$ is  given by:\n",
        "\\begin{equation}\n",
        "      y^i = \\textbf{w}^\\top \\textbf{x}^i + b + \\varepsilon.\n",
        "\\end{equation}\n",
        "\n",
        "Here, $\\varepsilon$ is an additive **noise** that corrupts the data generation process. (Think of a device that captures data where, during the capture process, the data gets corrupted with some noise.)\n",
        "\n",
        "In this example, let's set $\\textbf{w} = [2]$ and $b=4.2$.\n",
        "\n",
        "Let's create a class called **SyntheticRegressionData** whose responsibiity is to generate synthetic data following the description above:"
      ],
      "metadata": {
        "id": "9_W5wADsWi2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class SyntheticRegressionData:\n",
        "  def __init__(self, w, b, noise=0.01, num_train=1000):\n",
        "    self.n = num_train   # no. of trianing samples\n",
        "    self.w = w\n",
        "    self.b = b\n",
        "\n",
        "    # generate self.n samples. Each sample is of dimension length of self.w\n",
        "    self.X = torch.randn(self.n, len(self.w))\n",
        "\n",
        "    # Get a random noise\n",
        "    noise = torch.randn(self.n, 1) * noise\n",
        "\n",
        "    # For each sample in X, generate its corresponding y value\n",
        "    # using the equation above.\n",
        "    # Note below that the function reshape has parameters (-1, 1).\n",
        "    # This means that it will reshape the vector w into a 2D matrix where:\n",
        "    # - the 2nd dimension has length 1\n",
        "    # - the length of the first dimension will be autmatically set.\n",
        "    #\n",
        "    self.y = torch.matmul(self.X, w.reshape((-1, 1))) + b + noise\n"
      ],
      "metadata": {
        "id": "ot8TMZN-LCXv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's test this class by generating $n=1000$ data and plot them."
      ],
      "metadata": {
        "id": "85bADCVOORG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor([2.0])\n",
        "b = 4.2\n",
        "num_train = 1000\n",
        "noise = 1.2\n",
        "data = SyntheticRegressionData(w, b, noise, num_train)\n",
        "\n",
        "# Let's print some data samples\n",
        "print(data.X[0], data.y[0])"
      ],
      "metadata": {
        "id": "HGLMQr_TOajv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Often, we need to **plot** or **visualize** the data instead of printing individual numerical values. Python offers a range of tools for plotting data and graphs. For instance, in the simple example above, we can use the **plot** function from **matloplib**:"
      ],
      "metadata": {
        "id": "DGYXonscQgYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot as points in green\n",
        "plt.plot(data.X, data.y, 'r.')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Random data')"
      ],
      "metadata": {
        "id": "sTuNDt5ETm4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions:**\n",
        "\n",
        "\n",
        "1. Change the values of noise (make it smaller or bigger) and observe the plot that is generated.\n",
        "\n"
      ],
      "metadata": {
        "id": "HchH-_NYWFIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Write the code here and test it"
      ],
      "metadata": {
        "id": "jYtr2BJ0Wgaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Can the class above be used to generate high dimensionial data, e.g., 2D or 3D points, or even points in nD? Write below the Python code that would do that."
      ],
      "metadata": {
        "id": "_Ml0MykiWkkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Write the code here and test it\n",
        "\n",
        "w2 = torch.tensor([2.0, 3.0])\n",
        "b2 = 2.5\n",
        "num_train = 1000\n",
        "noise = 1.2\n",
        "data3 = SyntheticRegressionData(w2, b2, noise, num_train)\n",
        "\n",
        "print(data3.X.shape, data3.y.shape)"
      ],
      "metadata": {
        "id": "6_cMdn9kW5Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f5738f-cf7a-4945-cc96-1c5058684d65"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2]) torch.Size([1000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Analytical solution to the linear regression problem**\n",
        "\n",
        "Since this is a linear model, the solution has an analytical form. To simplify things, we add the bias $b$ to the vector $\\textbf{W}$. Thus, in what follows, $\\textbf{W} = (w_1, \\dots, w_d, b)^\\top$. We also add the element $1$ to each vector $\\textbf{x}^i$. With this notation, the solution of the equation above, i.e., the best values of the parameters $\\textbf{W}$, is given by:\n",
        "\n",
        "$$\n",
        "\\textbf{W}^*  = (\\textbf{X} \\textbf{X}^\\top)^{-1} \\textbf{X} \\textbf{y}.\n",
        "$$\n",
        "\n",
        "In the equation above:\n",
        "- $\\textbf{X}$ is a $(d+1) \\times n$ matrix, where each column is a training sample with the value $1$ appended to it. $n$ is the number of samples we generated\n",
        "- $\\textbf{X}^\\top$ means the transpose of the matrix $\\textbf{X}$.\n",
        "- The $-1$ exponent means the inverse of a matrix."
      ],
      "metadata": {
        "id": "3PdKVLn4V6dF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise 1 - Naive implementation**\n",
        "\n",
        "Using PyTorch, let's implement the analytical solution for the linear regression problem. We will then use the synthetic data generator we created above to test our solution."
      ],
      "metadata": {
        "id": "rBdVRILw-8bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1 - Generate some synthetic data\n",
        "w = torch.tensor([2.0])   # Note that the length of W is the dimension of the data\n",
        "b = 4.2\n",
        "num_train = 5\n",
        "noise = 0.01\n",
        "data = SyntheticRegressionData(w, b, noise, num_train)\n",
        "\n",
        "# Step 2 - linear regression\n",
        "# From this data, we need to recover w and b - let's call them w_star and b_star\n",
        "# Ideally, if our model is accurate, w_start and b_star should be equal to w and b, respectively\n",
        "# The they are to w and b, the better is our solution\n",
        "\n",
        "# 2.1. Add 1 at the end of X\n",
        "ones = torch.ones(data.n, 1)     # a column vector of ones\n",
        "X = torch.cat((data.X, ones), 1) # Append the columns of ones to the end of data.X. So I need to transpose it\n",
        "X = torch.transpose(X, 0, 1)\n",
        "\n",
        "# 2.2. The solution to the linear regression\n",
        "# print(data.X[0], data.y[0])\n",
        "A = torch.matmul(X, torch.transpose(X, 0, 1))\n",
        "# A should be of size d x d. To check it, uncomment the following\n",
        "# print(A.size())\n",
        "\n",
        "\n",
        "B = torch.matmul(torch.inverse(A), X)\n",
        "# print(B.size())\n",
        "\n",
        "w_estimated = torch.matmul(B, data.y)\n",
        "w_star = w_estimated[0:-1]    # get all the elements except the last one\n",
        "b_star = w_estimated[-1:]     # last element\n",
        "\n",
        "# print(w_estimated)\n",
        "print(\"Estimated W: \", w_star)\n",
        "print(\"Estimate b: \", b_star)\n",
        "\n",
        "# real values\n",
        "print(\"Real W: \", w)\n",
        "print(\"Real b: \", b)\n"
      ],
      "metadata": {
        "id": "ZQM5k4KxYk0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8666ae-c7ed-4616-b6f1-749383b05224"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated W:  tensor([[1.9956]])\n",
            "Estimate b:  tensor([[4.1967]])\n",
            "Real W:  tensor([2.])\n",
            "Real b:  4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** In the code above, try the followings:\n",
        "- Set the variable **noise** to $0$, and observe the results produced by the code.\n",
        "- Increase the amount of noise in the generated synthetic data, i.e., by setting the variable **noise** to larger values, and observe the results produced by the code.\n",
        "\n",
        "What can you say about the accuracy?"
      ],
      "metadata": {
        "id": "mc-3DATG0j_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise 2 - Analysis of the solution**\n",
        "\n",
        "What do you think would be the issues with the solution above? Think of:\n",
        "- The computation time: think first of what would be the issue and then test the code. You can add some code lines to check the computation time it takes to find te parameters $\\textbf{w}$ and $b$,  \n",
        "- The computation of the inverse of the matrix $\\textbf{X} \\textbf{X}^\\top$. Does the inverse always exist? If no, in which conditions it would not exist?"
      ],
      "metadata": {
        "id": "TvE31QHCzRrA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise 3 - Practical problem**\n",
        "\n",
        " We would like to write a code that predicts house prices based on their land **area** and **age**. We assume that the house price is a linear function of **area** and **age**.\n",
        "\n",
        "Use the classes you created above to solve this problem. To test your solution, use the synthetic data generator class to simulate some data. For example, you can simulate data by calling the class **SyntheticRegressionData** with the parameters $w_1 = 100, w_2 = -5, b=100$.\n",
        "\n",
        "Make sure you make the necessary changes to the solution above in order to solve this problem. However, when you make changes, make sure that the classes also work for the previous problem."
      ],
      "metadata": {
        "id": "WiCXDoJDyi0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the necessary code here\n",
        "\n",
        "# Price of a house is in a linear relationship to two of it's attributes, area and age.\n",
        "# So, I'll take w1 = area and w2 = age.\n",
        "# And now I need to create the synthetic data for this\n",
        "\n",
        "whouse = torch.tensor([100.0, -5.0]) #a tensor with 2 elements, so two features of the house\n",
        "bhouse = 100\n",
        "num_train = 1000\n",
        "noise = 1.2\n",
        "datahouse = SyntheticRegressionData(whouse, bhouse, noise, num_train)\n",
        "\n",
        "#print(datahouse.X.shape, datahouse.y.shape)\n",
        "# Expected output is torch.Size([1000, 2]) torch.Size([1000, 1])\n",
        "# At this point we have successfully created the synthetic data\n",
        "\n",
        "# Now, we use the analytical solution to get the w and b values that we set.\n",
        "# We can follow the example above\n",
        "\n",
        "# Add the ones to the end of the matrix X\n",
        "ones = torch.ones(datahouse.n, 1)\n",
        "X = torch.cat((datahouse.X, ones), 1)\n",
        "X = torch.transpose(X, 0, 1)\n",
        "\n",
        "# 2.2. The solution to the linear regression\n",
        "#print(data.X[0], data.y[0])\n",
        "A = torch.matmul(X, torch.transpose(X, 0, 1))\n",
        "# A should be of size d x d. To check it, uncomment the following\n",
        "#print(A.size())\n",
        "\n",
        "B = torch.matmul(torch.inverse(A), X)\n",
        "# print(B.size())\n",
        "\n",
        "w_estimated = torch.matmul(B, datahouse.y)\n",
        "w_star = w_estimated[0:-1]    # get all the elements except the last one\n",
        "b_star = w_estimated[-1:]     # last element\n",
        "\n",
        "# print(w_estimated)\n",
        "print(\"Estimated W: \", w_star)\n",
        "print(\"Estimate b: \", b_star)\n",
        "\n",
        "# real values\n",
        "print(\"Real W: \", whouse)\n",
        "print(\"Real b: \", bhouse)"
      ],
      "metadata": {
        "id": "tdpqXfkc7uei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d029ee5a-f76b-40da-d631-223230460ae7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated W:  tensor([[100.0191],\n",
            "        [ -5.0274]])\n",
            "Estimate b:  tensor([[100.0510]])\n",
            "Real W:  tensor([100.,  -5.])\n",
            "Real b:  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise 4 - Proper implementation**\n",
        "\n",
        "In the code above, we implemented the synthetic data generator as a class but the linear regression solver as part of the main code. In this exercise, let's also implement the solver as a class.\n",
        "\n",
        "To do so, we will create a class called LinearRegression. It will have at least the following parameters and methods as members:\n",
        "- The weights $\\textbf{W}$ and bias $b$. When the class is created, these weights will be initialized to random values. Note that, in the current solution, these weights can also be initialized to $0$. We will show later when using the general solution that initializing to $0$ is not a good idea.\n",
        "- The method **forward**, which takes an input $\\textbf{X}$ and computes its output $y$.\n"
      ],
      "metadata": {
        "id": "FPOaDtN916FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression:\n",
        "  def __init__(self, d=1):\n",
        "\n",
        "    self.dim = d  # dimension of the data\n",
        "\n",
        "    # Set the weights to random values from normal distribution of mean 0 and std 0.01\n",
        "    self.w = torch.randn(self.dim, 1) * 0.01\n",
        "    self.b = torch.randn(1, 1) * 0.01         # the bias\n",
        "\n",
        "  # The forward function, which computes y for a given X\n",
        "  def forward(self, X):\n",
        "    y = torch.matmul(self.X, w.reshape((-1, 1))) + b\n",
        "    return y\n",
        "\n"
      ],
      "metadata": {
        "id": "SJYzAsmj5mPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to define the training class, i.e., the class that takes the generated data, and then it fits to it the LinearRegression model (i.e, estimates the optimal parameters of the linear regression). Let's call it **Trainer**, which has at least the following members:\n",
        "- Method **fit()**, which takes as input the model (LinearRegression in our case) and the data (the synthetic data we generated in our case), and computes the optimal parameters **$\\textbf{W}$** and **$b$** of the model."
      ],
      "metadata": {
        "id": "jqJ0KaY-7gz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "  def __init__(self):\n",
        "    return\n",
        "\n",
        "  def fit(self, model, data):\n",
        "    # 2.1. Add 1 at the end of X\n",
        "    ones = torch.ones(data.n, 1)  # a column vector of ones\n",
        "    X = torch.cat((data.X, ones), 1)\n",
        "\n",
        "    # 2.2. The solution\n",
        "\n",
        "    # print(data.X[0], data.y[0])\n",
        "    A = torch.matmul(torch.transpose(X, 0, 1),X)\n",
        "    # A should be of size num_train x num_train. To check it, uncomment the following\n",
        "    # A.size()\n",
        "\n",
        "    B = torch.matmul(torch.inverse(A), torch.transpose(X, 0, 1))\n",
        "    # B.size()\n",
        "\n",
        "    w_estimated = torch.matmul(B, data.y)\n",
        "    model.w = w_estimated[0:-1]    # get all the elements except the last one\n",
        "    model.b = w_estimated[-1:]     # last element\n"
      ],
      "metadata": {
        "id": "5d_Ox3vE8b7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's write the code of the main function:"
      ],
      "metadata": {
        "id": "YRAiwYYu9deV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. The data\n",
        "d = 1   # dimension of the data\n",
        "w = torch.tensor([2.0])\n",
        "b = 4.2\n",
        "num_train = 1000\n",
        "noise = 0.01\n",
        "data = SyntheticRegressionData(w, b, noise, num_train)\n",
        "\n",
        "# 2. The model (linear regression)\n",
        "model = LinearRegression(d)\n",
        "\n",
        "# 3. The trainer\n",
        "trainer = Trainer()\n",
        "\n",
        "# 4. Estimate the parameters\n",
        "trainer.fit(model, data)\n",
        "\n",
        "# 5. Get the results\n",
        "w_star = model.w\n",
        "b_star = model.b\n",
        "\n",
        "# print(w_estimated)\n",
        "print(\"Estimated W: \", w_star)\n",
        "print(\"Estimate b: \",  b_star)\n",
        "\n",
        "# real values\n",
        "print(\"Real W: \", w)\n",
        "print(\"Real b: \", b)"
      ],
      "metadata": {
        "id": "lkrOQL729lQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the code above on multidimensional data (e.g., 2D or 3D)."
      ],
      "metadata": {
        "id": "2vmq48DqZWNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Exercise 5 - Another problem**\n",
        "\n",
        "Suppose now that the problem we would like to solve is:\n",
        "$$\n",
        "y = \\sum_{i=1}^{d}w_ix_i^2 + b,\n",
        "$$\n",
        "where $x_i \\in \\mathbb{R}$, i.e., $x_i$'s are one-dimensinal scalars. How would you extend the implementation above to solve this problem? Can you think of a better Object-Oriented Design that will make our implementation generic, so that it can be extended with minimum efforts to other machine learning models?"
      ],
      "metadata": {
        "id": "Pj7e5wRlZiAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Reusable implementation**\n",
        "\n",
        "In the examples above, we wrote all the code in the google colab notebook. Thus, the classes and methods we created cannot be reused elsewhere. In this exercise, create your first library of classes saved into python files (.py), and write here the test code that uses them."
      ],
      "metadata": {
        "id": "hv6ni-OiUuzE"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}