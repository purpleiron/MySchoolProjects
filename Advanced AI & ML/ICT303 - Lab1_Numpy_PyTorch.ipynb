{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdDimpLi2_nI"
      },
      "source": [
        "# **ICT303 - Advanced Machine Learning and Artificial Intelligence**\n",
        "# **Lab 1 - Introduction to Python, NumPy and Torch**\n",
        "\n",
        "The purpose of this lab is to provide you with the Python toolkit you will be using in this unit. This includes:\n",
        "- Familiarizing yourself with Python programming. Although there is no unit within the IT degree that explicitly teaches Python, as an IT student of Murdoch, you should by now have learned C, Java and C++. These are the foundations that will enable you to learn any other programming language by your own. In fact,  as an IT expert, you MUST learn how to learn by yourself.\n",
        "- Familiarize yourself with some important Python libraries that we will be using during the semester. These include NumPy and PyTorch.\n",
        "\n",
        "Note that, Section 2 of this lab has been adapted from https://numpy.org/doc/stable/user/quickstart.html. Sections 3 onwards have been adapted from https://deeplearning.cs.cmu.edu/F20/index.html."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Python**\n",
        "\n",
        "In this unit, we will use the [*Colab research platform*](https://colab.research.google.com/) for programming. Since you are reading this, it means you have already created a Google account and managed to open this Colab notebook.\n",
        "\n",
        "Note also that you can open this document using Jupiter Notebook.\n",
        "\n",
        "Before you continue, I recommend to create a folder named ICT303 in your Google drive, and make sure you save all your work (i.e., the notebooks and associated files your will create as part of this unit) in it.\n",
        "\n",
        "You can find more information on how to use Colab and its features in the link above.\n",
        "\n",
        "Note also that Colab integrates cleanly with Github, allowing both loading notebooks from Github and saving notebooks into Github. You can find more details about this functionality here: https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb.\n",
        "\n",
        "Once done, it is time for you to learn a little bit about Python. There are plenty of online resources that you can use. I recommend downloading this tutorial notebook from CMU: https://deeplearning.cs.cmu.edu/F20/document/recitation/Rec_0A_Fundamentals_of_Python.zip\n",
        "- Download the notebook and then upload it to your google drive and view it in Colab.\n",
        "- Work through the tutorial step by step.\n",
        "\n",
        "Note that you do not need to do the entire Python tutorial. Scheme through it and try to:\n",
        "- Understand the structure of a Python program\n",
        "- How to create classes and methods (functions)\n",
        "- How to pass in parameters into functions and return values in functions.\n",
        "\n",
        "Then, use the tutorial as a reference whenever you need to create something with Python."
      ],
      "metadata": {
        "id": "RNeECLiQOUgc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIidViuPvPAR"
      },
      "source": [
        "\n",
        "### **2. NumPy**\n",
        "\n",
        "The first library of interest is [NumPy](http://www.numpy.org/). You can find more details about NumPy at https://numpy.org/doc/stable/user/quickstart.html.  You can also go through this CMU tutorial: https://deeplearning.cs.cmu.edu/F20/document/recitation/Rec_0B_Fundamentals_of_Numpy.zip\n",
        "\n",
        "In this document, I will summarize some of the most important features of NumPy.\n",
        "\n",
        "NumPy is the fundamental package for scientific computing with Python. It contains, among other things:\n",
        "\n",
        "- A powerful N-dimensional array object that allows you to manipulate N-dimensional arrays,\n",
        "- Sophisticated (broadcasting) functions. The term broadcasting describes how NumPy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is “broadcast” across the larger array so that they have compatible shapes.\n",
        "- Tools for integrating C/C++ and Fortran code\n",
        "- Useful linear algebra, Fourier transform, and random number generation capabilities\n",
        "\n",
        "Besides its obvious scientific uses, NumPy can also be used as an efficient multi-dimensional container of generic data. Arbitrary data types can be defined. This allows NumPy to seamlessly and speedily integrate with a wide variety of databases."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1. The Basics**\n",
        "\n",
        "NumPy’s main object is the homogeneous multidimensional array. It is a table of elements (usually numbers), all of the same type, indexed by a tuple of non-negative integers. In NumPy, dimensions are called **axes**.\n",
        "\n",
        "NumPy arrays are called **ndarray** and are defined in the package **numpy.array**.\n",
        "\n",
        "****Example 1 - A point or vector in 3D space:****\n",
        "A point in 3D space has 3 coordinates (x, y, z). Similarly, a vector in 3D space has 3 coordinates (x, y, z). Thus, from the programming point of view, they can both be defined using an array of 3 elements. Using NumPy **ndarray**, they can be defined as an array that has one axis (one dimension). For example:"
      ],
      "metadata": {
        "id": "2mMd2VCSVwpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## A point in 3D space\n",
        "p = [1, 2, 1]\n",
        "\n",
        "## A vector in 3D space\n",
        "v = [3, 2.1, 5]\n",
        "\n",
        "## printing\n",
        "print(\"The point is: \")\n",
        "print(p)\n",
        "print(\"The vector is: \")\n",
        "print(v)"
      ],
      "metadata": {
        "id": "RSu4krOC2pRM",
        "outputId": "280b85f7-9763-4bcb-d8a7-285afe574355",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The point is: \n",
            "[1, 2, 1]\n",
            "The vector is: \n",
            "[3, 2.1, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Example 2 - A list of 3D points***\n",
        "\n",
        "Assume that we would like to create a data structure that will hold a list of 3D points.  Using NumPy's **ndarray**, it can be defined using an array that has two axes:\n",
        "\n"
      ],
      "metadata": {
        "id": "k6fjfFxA3wU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "vertices =np.array([[1, 0, 0],\n",
        "           [3, 2, 0.1],\n",
        "           [-1.3, 2.4, 5],\n",
        "           [5.3, 3, -2.3]])\n",
        "# Printing - method 1\n",
        "print(vertices)\n",
        "\n",
        "# Printing - method 2\n",
        "vertices\n",
        "\n",
        "# Printing the first point or row (of index 0)\n",
        "print(vertices[0,])\n",
        "\n",
        "# Printing the first column (of index 0)\n",
        "print(vertices[:,0])"
      ],
      "metadata": {
        "id": "0V0NG_re4aJD",
        "outputId": "b146c519-e7e4-4af6-f44b-2d3042e88f23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.   0.   0. ]\n",
            " [ 3.   2.   0.1]\n",
            " [-1.3  2.4  5. ]\n",
            " [ 5.3  3.  -2.3]]\n",
            "[1. 0. 0.]\n",
            "[ 1.   3.  -1.3  5.3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This ndarray has two axes. The first axis has a length of 4 The number of rows). The second axis has a length of 3 (the number of columns).\n",
        "\n",
        "The class ndarray has many important attributes. The most important ones include:\n",
        "\n",
        "- ***ndarray.ndim*** - The number of axes (dimensions) of the array.\n",
        "\n",
        "- ***ndarray.shape*** - the dimensions of the array. This is a tuple of integers indicating the size of the array in each dimension. For a matrix with $n$ rows and $m$ columns, shape will be $(n,m)$. The length of the shape tuple is therefore the number of axes, ndim.\n",
        "\n",
        "- ***ndarray.size*** - the total number of elements of the array. This is equal to the product of the elements of shape.\n",
        "\n",
        "- ***ndarray.dtype*** - an object describing the type of the elements in the array. One can create or specify dtype using standard Python types. Additionally, NumPy provides types of its own: `numpy.int32`, `numpy.int16`, and `numpy.float64` are some examples.\n",
        "\n",
        "- ***ndarray.itemsize*** - the size in bytes of each element of the array. For example, an array of elements of type float64 has itemsize equal to 8 (i.e., 64/8), while one of type complex32 has itemsize equal to 4 (i.e., 32/8). It is equivalent to `ndarray.dtype.itemsize`.\n",
        "\n",
        "- ***ndarray.data*** - the buffer containing the actual elements of the array. Normally, we won’t need to use this attribute because we will access the elements in an array using indexing facilities.\n",
        "\n",
        "***Example 3.***  Try these properties on the examples defined above."
      ],
      "metadata": {
        "id": "-dt-xh2k4n8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2. Creating and printing NumPy arrays**\n",
        "\n",
        "Please refer to Sections ***Array Creation*** and ***Printing Arrays*** of https://numpy.org/doc/stable/user/quickstart.html\n",
        "\n",
        "***Example 4***: Create a random 1D array of size $32$. Then try to:\n",
        "- Reshape the 1D array into a 2D array of size $8 \\times 4$ (i.e., axes 1 will have size $8$ while axes $2$ will have size $4$). Use the function numpy.arrange. For this, please refer to https://numpy.org/doc/stable/reference/generated/numpy.reshape.html\n",
        "- Display (print) the results.\n",
        "\n",
        "As a bonus question, try to rearrange the 2D array into a 1D array. For this, check the different parameters of the function reshape, especially the last parameter which takes one of the three values: 'C', 'F', and 'A'. Please refer to https://numpy.org/doc/stable/reference/generated/numpy.reshape.html."
      ],
      "metadata": {
        "id": "3PdKVLn4V6dF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.3. Basic Operations**\n",
        "\n",
        "You can do arithmetic operations (additions, subtractions, multiplications) on NumPy arrays. These will be applied element wise. For example, to add two arrays ***A*** and ****B***  of same dimension, you do not need to write a loop through its elements, you just need to write ***A+B***. Please refer to the section ***Basic Operations*** of https://numpy.org/doc/stable/user/quickstart.html.\n",
        "\n",
        "It is important to pay attention to some aspects that are specific to NumPy arrays. In particular, the product operator *  operates elementwise in NumPy array. If you want to use matrix product, then you have to use the operator ***@*** (in Python > 3.5) or the ***dot*** function. Please refer to https://numpy.org/doc/stable/user/quickstart.html for more details.\n",
        "\n",
        "The example below illustrates this concept."
      ],
      "metadata": {
        "id": "bNaMAvAwV-51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[1, 1],\n",
        "              [0, 1]])\n",
        "B = np.array([[2, 0],\n",
        "              [3, 4]])\n",
        "C1 = A * B     # elementwise product\n",
        "\n",
        "C2 = A @ B     # matrix product\n",
        "\n",
        "C3 = A.dot(B)  # another matrix product\n",
        "\n",
        "print (C1)\n",
        "print (C2)\n",
        "print (C3)"
      ],
      "metadata": {
        "id": "WpFw1Aj4MQCz",
        "outputId": "c0215024-7c44-440b-ecca-551db106860f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 0]\n",
            " [0 4]]\n",
            "[[5 4]\n",
            " [3 4]]\n",
            "[[5 4]\n",
            " [3 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note also that the NumPy array class provides methods such as `sum`, `min`, `max`, etc., which operate on the entire elements of the array. By default, these operations apply to the array as though it were a list of numbers, regardless of its shape. However, by specifying the axis parameter you can apply an operation along the specified axis of an array:\n",
        "\n"
      ],
      "metadata": {
        "id": "Umx8rVz7Mrc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = np.arange(12).reshape(6, 2)\n",
        "print (b)                 # Printing b\n",
        "\n",
        "a = b\n",
        "a = a.reshape(3,4)\n",
        "print (a)\n",
        "print (b)\n",
        "#print(b.sum(axis=0))     # sum of each column\n",
        "\n",
        "#print(b.min(axis=1))     # min of each row\n",
        "\n",
        "#print(b.cumsum(axis=1))  # cumulative sum along each row"
      ],
      "metadata": {
        "id": "QW6zhR_GNFes",
        "outputId": "64658a92-9ec5-43d3-98de-83664b17b694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1]\n",
            " [ 2  3]\n",
            " [ 4  5]\n",
            " [ 6  7]\n",
            " [ 8  9]\n",
            " [10 11]]\n",
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]]\n",
            "[[ 0  1]\n",
            " [ 2  3]\n",
            " [ 4  5]\n",
            " [ 6  7]\n",
            " [ 8  9]\n",
            " [10 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy also provides common mathematical functions such as `exp` (for exponential), `sqrt` (for square root), etc.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PIzFyAkcNSsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.4. Indexing, Slicing and Iterating**\n",
        "\n",
        "One-dimensional arrays can be indexed, sliced and iterated over, much like lists and other Python sequences."
      ],
      "metadata": {
        "id": "0fs4V3h4a9_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An array of 10 elements with values [0, 1, , ..., 9] and make every element power 3\n",
        "a = np.arange(10)\n",
        "a\n",
        "\n",
        "# First element\n",
        "print(\"First element: \")\n",
        "a[0]\n",
        "\n",
        "# Last element\n",
        "print(\"Last element: \")\n",
        "a[-1]\n",
        "\n",
        "# Print the 3rd element - Similar to C, array indices start from 0\n",
        "print(\"3rd element: \")\n",
        "a[2]\n",
        "\n",
        "# Print the elements index between 2 to 5\n",
        "print(\"Elements from 2 to 5: \")\n",
        "a[2:5]\n",
        "\n",
        "# From start to position 6, exclusive, set every 2nd element to 1000\n",
        "# This is equivalent to a[0:6:2] = 1000;\n",
        "a[:6:2] = 1000\n",
        "a\n",
        "\n",
        "# Reverse the array a, i.e., last element becomes first, etc.\n",
        "a[::-1]\n",
        "\n",
        "# Looping through the elements of a\n",
        "for x in a:\n",
        "    print(x)"
      ],
      "metadata": {
        "id": "W8fVSaA0gumu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multidimensional** arrays can have one index per axis. These indices are given in a tuple separated by commas.\n",
        "\n",
        "When fewer indices are provided than the number of axes, the missing indices are considered complete slices. For instance, in the example below, `b[1]` is the same as `b[1, :] `and is also the same as `b[1, ...`] where the three dots mean the remaining dimensions."
      ],
      "metadata": {
        "id": "uvGC2IJCjpgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "b = np.array([[ 0,  1,  2,  3],\n",
        "              [10, 11, 12, 13],\n",
        "              [20, 21, 22, 23],\n",
        "              [30, 31, 32, 33],\n",
        "              [40, 41, 42, 43]])\n",
        "\n",
        "print(b[3,:2])\n",
        "\n",
        "print(b[1,:])\n",
        "\n",
        "print(b[1, ...])"
      ],
      "metadata": {
        "id": "WYN8G7T-kH50",
        "outputId": "e6d7c047-a999-4b9a-aa78-f296f887f848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30 31]\n",
            "[10 11 12 13]\n",
            "[10 11 12 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iterating** over multidimensional arrays is done with respect to the first axis:"
      ],
      "metadata": {
        "id": "4WEZIsI0pkrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for row in b:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "id": "cOVFAJprzHyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example above, if `b` had three axes (dimensions) then row will have two dimensions.\n",
        "\n"
      ],
      "metadata": {
        "id": "JXhFGOvpzOg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.5. Shape manipulation**\n",
        "\n",
        "The shape of an array is the number of elements it has along each axis. You can change this shape by\n",
        "- flattening it (e.g., 2D array  becomes one long 1D array) using the method `ravel()`\n",
        "- reshape it. For example, if you have an array of 3 rows and 4 columns,  you can reshape it into an array of 6 rows and 2 columns using the method `reshape()`.\n"
      ],
      "metadata": {
        "id": "y2FxZxNrbSZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **2.6. Other matters**\n",
        "\n",
        "You can stack together several arrays along different axis to form a new array. You can also split one array into several smaller ones.\n",
        "\n",
        "It also important to pay attention to how arrays are copied. Copying an array variabe into another variable can be done in different ways:\n",
        "- A simple assignment `b = a` does not make a separate (new) copy of `a`. Instead, `b` becomes a new name for the same ndarray.\n",
        "- Viewer or shallow copy using the view method which creates a new array that looks at the same data. Also, slicing an array returns a view of it.\n",
        "- Deep copy using the method `copy()`.\n",
        "\n",
        "Please refer to https://numpy.org/doc/stable/user/quickstart.html for more advanced topics related to NumPy arrays, including tricks and tips!"
      ],
      "metadata": {
        "id": "MYiJOB7obU0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. PyTorch**\n",
        "\n",
        "The second library of interest is PyTorch, which is an open-source deep learning library (called also frameowrk) for python, and will be extensively used throughout this unit.\n",
        "\n",
        "Note that PyTorch is not only deep learning framework that one can use. Other popular and commonly used frmeworks include TensorFlow, MXNet, PyTorch  Lightning, etc.\n",
        "\n",
        "You can install PyTorch on your local machine by referring to https://PyTorch.org/get-started/locally/.\n",
        "\n",
        "PyTorch is an open source deep learning platform that provides a seamless path from research prototyping to production deployment.\n",
        "> - *Hybrid Front-End:* A new hybrid front-end seamlessly transitions between eager mode and graph mode to provide both flexibility and speed.\n",
        "> - *Distributed Training:* Scalable distributed training and performance optimization in research and production is enabled by the torch.distributed backend.\n",
        "> - *Python-First:* Deep integration into Python allows popular libraries and packages to be used for easily writing neural network layers in Python.\n",
        "> - *Tools & Libraries:* A rich ecosystem of tools and libraries extends PyTorch and supports development in computer vision, NLP and more.\n",
        ">\n",
        "> To learn more about PyTorch and expand your knowledge, please refer to [About PyTorch](https://pytorch.org/)*\n",
        "\n",
        "One consideration as to why we are using PyTorch is most succinctly summerized by Andrej Karpathy, Director of Artificial Intelligence and Autopilot Vision at Tesla. The technical summary can be found [here](https://twitter.com/karpathy/status/868178954032513024?lang=en).\n",
        "\n",
        "To use PyTorch in colab, please refer to https://colab.research.google.com/github/omarsar/pytorch_notebooks/blob/master/pytorch_quick_start.ipynb.\n",
        "\n",
        "You can use the code below to check whether PyTorch is properly installed and which version is installed."
      ],
      "metadata": {
        "id": "PHSTcbsL2XI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking that PyTorch is running\n",
        "\n",
        "import torch\n",
        "\n",
        "# Check the version\n",
        "print(torch.__version__)\n",
        "\n"
      ],
      "metadata": {
        "id": "lOPQMpSYb62l",
        "outputId": "85d600e8-44bc-40b4-a6f9-57913e18e4c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creare a simple Tensor\n",
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "esGqXMbWQhrw"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the fundamental concepts in PyTorch is the **Tensor**, a multi-dimensional matrix containing elements of a single type. Tensors are similar to numpy nd-arrays and tensors support most of the functionality that numpy matrices do.\n",
        "\n",
        "Please go through this guide: https://pytorch.org/tutorials/ to learn about PyTorch, from the basics to advanced topics. Many of the examples are about deep learning - don't worry about them at this stage. Below are the topics that you need to familiarize yourself with at this stage.\n",
        "\n",
        "Start by familiarizing yourself with ***the basics*** at: https://pytorch.org/tutorials/beginner/basics/intro.html. You should learn about:\n",
        "- **Tensors:** These are a specialized data structure, very similar to arrays and matrices. Tensors in PyTorch are used to encode inputs and outputs of a model (neural network), as well as the model's parameters. They are similar to NumPy's ndarrays, except that tensors can run on GPUs or other hardware accelerators.  In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data.\n",
        "- **Datasets and DataLoaders:** PyTorch offers ready-to-use classes and functions for loading standard datasets used to train neural networks.\n",
        "\n",
        "The Quick Start section of the tutorial above provides a quick overview of the functionalities available\n",
        "\n",
        "Once we advance in the unit and you learn about neural networks, then you need to familiarize yourself with the following topics:\n",
        "- **Transforms:** i.e., how to transform the data to make it suitable for training neural neytworks.\n",
        "- **Build model:** to build neural network models.\n",
        "- **Automatic differentiation:** I will talk about this later in the lecture.\n",
        "- **Optimization loop:** I will talk about this later in the lecture.\n",
        "\n",
        "This week, make sure that you familiarize yourself with **Tensors**. You need to know:\n",
        "- How to create tensors directly from data, from another NumPy array, and from another Tensor.\n",
        "- Attributes of a Tensor.\n",
        "- Operations on Tensors, including indexing and slicing."
      ],
      "metadata": {
        "id": "bhbrIKxucLSd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWrt-C9Vsp5C"
      },
      "source": [
        "### **4. Practice what you learned**\n",
        "\n",
        "In the following exercises, you will familiarize yourself with tensors and more importantly, the PyTorch documentation. It is important to note that for this section, we are simply using PyTorch’s tensors as a matrix library, just like numpy. So please do not use functions in `torch.nn` such as `torch.nn.ReLU`.\n",
        "\n",
        "In PyTorch, it is very simple to convert between numpy arrays and tensors. PyTorch’s tensor library provides functions to perform the conversion in either direction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p9YQe_uDi61"
      },
      "source": [
        "#### **4.1. Converting from NumPy to PyTorch Tensor**\n",
        "In this task, you will implement a conversion function from arrays to tensors.\n",
        "\n",
        "The function should take a numpy ndarray and convert it to a PyTorch tensor.\n",
        "\n",
        "*Function torch.tensor is one of the simple ways to implement it.*\n",
        "\n",
        "**Your Task**: Implement the function `numpy2tensor`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klJEQtx7FGAH"
      },
      "outputs": [],
      "source": [
        "def numpy2tensor(x):\n",
        "    conv = torch.tensor(x)\n",
        "\n",
        "    return conv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPckbKJpFHr4"
      },
      "source": [
        "**Test Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZjTdpA1FKFx",
        "outputId": "8939241a-1c82-469c-db6a-470c92e1db0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "X = np.random.randint(-1000, 1000, size=3000)\n",
        "\n",
        "print(type(numpy2tensor(X)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXW0LdfbFOFK"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> type(numpy2tensor(X)) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt> &lt;class &#39;torch.Tensor&#39;&gt; </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXm9FUllFSSw"
      },
      "source": [
        "#### **4.2. Converting from PyTorch Tensor to NumPy**\n",
        "\n",
        "In this task, you will implement a conversion function from tensors to arrays.\n",
        "\n",
        "The function should take a PyTorch tensor and convert it to a numpy ndarray.\n",
        "\n",
        "**Your Task**: Implement the function `tensor2numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls7nSxDfFoK2"
      },
      "outputs": [],
      "source": [
        "def tensor2numpy(x):\n",
        "    conv = x.numpy()\n",
        "\n",
        "    return conv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hzuBTxuFqSY"
      },
      "source": [
        "**Test Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXi-bI3TFsZs",
        "outputId": "b21d94b7-ed10-46e0-c72d-7caa453fa21e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "X = np.random.randint(-1000, 1000, size=3000)\n",
        "X = torch.from_numpy(X)\n",
        "\n",
        "print(type(tensor2numpy(X)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scUXKxnyFxVK"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> type(tensor2numpy(X)) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt> &lt;class &#39;numpy.ndarray&#39;&gt; </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOF0T1j22_nv"
      },
      "source": [
        "### **5. Vectorization**\n",
        "\n",
        "Lists are a foundational data structure in Python, allowing us to create simple and complex algorithms to solve problems. However, in mathematics and particularly in linear algebra, we work with vectors and matrices to model problems and create statistical solutions. Through these exercises, we will begin introducing you to how to think more mathematically through the use of NumPy by starting with a process known as vectorization.\n",
        "\n",
        "Index chasing is a very valuable skill, and certainly one you will need in this course, but mathematical problems often have simpler and more efficient representations that use vectors. The process of converting from an implementation that uses indices to one that uses vectors is known as **vectorization**. Once vectorized, the resulting implementation often yields to a faster and more readable code than before.\n",
        "\n",
        "In the following problems, we will ask you to practice reading mathematical expressions and deduce their vectorized equivalent along with their implementation in Python. You will use the NumPy array object as the Python equivalent to a vector, and in latter sections you will work with sets of vectors known as matrices.\n",
        "\n",
        "For the following tasks, you will be asked to complete the same task first using **NumPy** operations, then again using **PyTorch** operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL6DGOa52_nx"
      },
      "source": [
        "#### **5.1. Dot Product**\n",
        "\n",
        "In this task, you will implement the dot product function for numpy arrays and pytorch tensors.\n",
        "\n",
        "The dot product (also known as the scalar product or inner product) is the linear combination of the $n$ real components of two vectors $\\textbf{x} = (x_1,x_2, ...)^T$ and $\\textbf{y}=(y_1, y_2, ...)^T$.\n",
        "\n",
        "$$\\textbf{x} \\cdot \\textbf{y} = x_1 y_1 + x_2 y_2 + \\cdots + x_n y_n$$\n",
        "\n",
        "**Your Task**: Implement the functions `NUMPY_dot` & `PYTORCH_dot`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "t7_t_pOq2_ny"
      },
      "outputs": [],
      "source": [
        "def EXAMPLE_inefficient_dot(x, y):\n",
        "    \"\"\"\n",
        "    Inefficient dot product of two arrays.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 1-dimensional numpy array.\n",
        "    y (numpy.ndarray): 1-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy.int64: scalar quantity.\n",
        "    \"\"\"\n",
        "    assert(len(x) == len(y))\n",
        "\n",
        "    result = 0\n",
        "    for i in range(len(x)):\n",
        "        result += x[i]*y[i]\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "8OgI9XvP2_nz"
      },
      "outputs": [],
      "source": [
        "def NUMPY_dot(x, y):\n",
        "    \"\"\"\n",
        "    Dot product of two arrays.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 1-dimensional numpy array.\n",
        "    y (numpy.ndarray): 1-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy.int64: scalar quantity.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    return x @ y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "k6Vt0Q0pH74V"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_dot(x, y):\n",
        "    \"\"\"\n",
        "    Dot product of two tensors.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 1-dimensional torch tensor.\n",
        "    y (torch.Tensor): 1-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.int64: scalar quantity.\n",
        "    \"\"\"\n",
        "\n",
        "    return x @ y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u80TqwMI2_nz"
      },
      "source": [
        "**Test Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "zeZu1Amf2_n0",
        "outputId": "7ce74cb7-53a3-4a46-9bc6-f36bd61cc4ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7082791\n",
            "tensor(7082791)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=3000)\n",
        "Y = np.random.randint(-1000, 1000, size=3000)\n",
        "\n",
        "print(NUMPY_dot(X,Y))\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "Y = torch.from_numpy(Y)\n",
        "print(PYTORCH_dot(X,Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A74YyJgJ2_n1"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> NUMPY_dot(X,Y) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt> 7082791 </tt></td>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_dot(X,Y) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt> 7082791 </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIJf-ImY2_n2"
      },
      "source": [
        "#### **5.2. Outer Product**\n",
        "\n",
        "In this task, you will implement the outer product function for numpy arrays & torch tensors.\n",
        "\n",
        "The outer product (also known as the tensor product) of vectors $\\textbf{x}$ and $\\textbf{y}$ is defined as\n",
        "\n",
        "$$\n",
        "\\textbf{x} \\otimes \\textbf{y} =\n",
        "\\begin{bmatrix}\n",
        "x_1 y_1 & x_1 y_2 & … & x_1 y_n\\\\\n",
        "x_2 y_1 & x_2 y_2 & … & x_2 y_n\\\\\n",
        "⋮ & ⋮ & ⋱ & ⋮ \\\\\n",
        "x_m y_1 & x_m y_2 & … & x_m y_n\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Your Task**: Implement the functions `NUMPY_outer` & `PYTORCH_outer`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "kKidI4262_n3"
      },
      "outputs": [],
      "source": [
        "def EXAMPLE_inefficient_outer(x, y):\n",
        "    \"\"\"\n",
        "    Inefficiently compute the outer product of two vectors.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 1-dimensional numpy array.\n",
        "    y (numpy.ndarray): 1-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: 2-dimensional numpy array.\n",
        "    \"\"\"\n",
        "    result = np.zeros((len(x), len(y)))\n",
        "    for i in range(len(x)):\n",
        "        for j in range(len(y)):\n",
        "            result[i, j] = x[i]*y[j]\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "NBg_pnlb2_n4"
      },
      "outputs": [],
      "source": [
        "def NUMPY_outer(x, y):\n",
        "    \"\"\"\n",
        "    Compute the outer product of two vectors.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 1-dimensional numpy array.\n",
        "    y (numpy.ndarray): 1-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: 2-dimensional numpy array.\n",
        "    \"\"\"\n",
        "\n",
        "    return np.outer(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "q7JXJcKMKGA-"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_outer(x, y):\n",
        "    \"\"\"\n",
        "    Compute the outer product of two vectors.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 1-dimensional torch tensor.\n",
        "    y (torch.Tensor): 1-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: 2-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    return torch.outer(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYdW53b_2_n4"
      },
      "source": [
        "**Test Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "DFdGvph72_n5",
        "outputId": "1ab4841a-c194-4252-deb1-3b8e177bbecc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  59092 -144096  136512 ...  -53088  -86268   53404]\n",
            " [  82467 -201096  190512 ...  -74088 -120393   74529]\n",
            " [-122111  297768 -282096 ...  109704  178269 -110357]\n",
            " ...\n",
            " [-144551  352488 -333936 ...  129864  211029 -130637]\n",
            " [-179707  438216 -415152 ...  161448  262353 -162409]\n",
            " [  88825 -216600  205200 ...  -79800 -129675   80275]]\n",
            "tensor([[  59092, -144096,  136512,  ...,  -53088,  -86268,   53404],\n",
            "        [  82467, -201096,  190512,  ...,  -74088, -120393,   74529],\n",
            "        [-122111,  297768, -282096,  ...,  109704,  178269, -110357],\n",
            "        ...,\n",
            "        [-144551,  352488, -333936,  ...,  129864,  211029, -130637],\n",
            "        [-179707,  438216, -415152,  ...,  161448,  262353, -162409],\n",
            "        [  88825, -216600,  205200,  ...,  -79800, -129675,   80275]])\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=3000)\n",
        "Y = np.random.randint(-1000, 1000, size=3000)\n",
        "\n",
        "\n",
        "print(NUMPY_outer(X,Y))\n",
        "#EXAMPLE_inefficient_outer(X, Y)\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "Y = torch.from_numpy(Y)\n",
        "\n",
        "print(PYTORCH_outer(X,Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiVgEuI12_n6"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> NUMPY_outer(X,Y) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [[&nbsp;&nbsp;59092&nbsp;-144096&nbsp;&nbsp;136512&nbsp;...&nbsp;&nbsp;-53088&nbsp;&nbsp;-86268&nbsp;&nbsp;&nbsp;53404] <br>\n",
        "            &nbsp;[&nbsp;&nbsp;82467&nbsp;-201096&nbsp;&nbsp;190512&nbsp;...&nbsp;&nbsp;-74088&nbsp;-120393&nbsp;&nbsp;&nbsp;74529] <br>\n",
        "            &nbsp;[-122111&nbsp;&nbsp;297768&nbsp;-282096&nbsp;...&nbsp;&nbsp;109704&nbsp;&nbsp;178269&nbsp;-110357] <br>\n",
        "            &nbsp;... <br>\n",
        "            &nbsp;[-144551&nbsp;&nbsp;352488&nbsp;-333936&nbsp;...&nbsp;&nbsp;129864&nbsp;&nbsp;211029&nbsp;-130637] <br>\n",
        "            &nbsp;[-179707&nbsp;&nbsp;438216&nbsp;-415152&nbsp;...&nbsp;&nbsp;161448&nbsp;&nbsp;262353&nbsp;-162409] <br>\n",
        "            &nbsp;[&nbsp;&nbsp;88825&nbsp;-216600&nbsp;&nbsp;205200&nbsp;...&nbsp;&nbsp;-79800&nbsp;-129675&nbsp;&nbsp;&nbsp;80275]] <br>\n",
        "        </tt></td>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_outer(X,Y) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [[&nbsp;&nbsp;59092&nbsp;-144096&nbsp;&nbsp;136512&nbsp;...&nbsp;&nbsp;-53088&nbsp;&nbsp;-86268&nbsp;&nbsp;&nbsp;53404] <br>\n",
        "            &nbsp;[&nbsp;&nbsp;82467&nbsp;-201096&nbsp;&nbsp;190512&nbsp;...&nbsp;&nbsp;-74088&nbsp;-120393&nbsp;&nbsp;&nbsp;74529] <br>\n",
        "            &nbsp;[-122111&nbsp;&nbsp;297768&nbsp;-282096&nbsp;...&nbsp;&nbsp;109704&nbsp;&nbsp;178269&nbsp;-110357] <br>\n",
        "            &nbsp;... <br>\n",
        "            &nbsp;[-144551&nbsp;&nbsp;352488&nbsp;-333936&nbsp;...&nbsp;&nbsp;129864&nbsp;&nbsp;211029&nbsp;-130637] <br>\n",
        "            &nbsp;[-179707&nbsp;&nbsp;438216&nbsp;-415152&nbsp;...&nbsp;&nbsp;161448&nbsp;&nbsp;262353&nbsp;-162409] <br>\n",
        "            &nbsp;[&nbsp;&nbsp;88825&nbsp;-216600&nbsp;&nbsp;205200&nbsp;...&nbsp;&nbsp;-79800&nbsp;-129675&nbsp;&nbsp;&nbsp;80275]] <br>\n",
        "        </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKeK_i3f2_n8"
      },
      "source": [
        "#### **5.3. Hadamard Product**\n",
        "\n",
        "In this task, you will implement the Hadamard product function, `multiply`, for numpy arrays & torch tensors.\n",
        "\n",
        "The Hadamard product (also known as the Schur product or entrywise product) of vectors $\\textbf{x}$ and $\\textbf{y}$ is defined as\n",
        "\n",
        "$$\n",
        "\\textbf{x} \\circ \\textbf{y} =\n",
        "\\begin{bmatrix}\n",
        "x_{1} y_{1} & x_{2} y_{2} & … & x_{n} y_{n}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Your Task**: Implement the functions `NUMPY_multiply` & `PYTORCH_multiply`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "i5b2GYkT2_n-"
      },
      "outputs": [],
      "source": [
        "def EXAMPLE_inefficient_multiply(x, y):\n",
        "    \"\"\"\n",
        "    Inefficiently multiply arguments element-wise.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 1-dimensional numpy array.\n",
        "    y (numpy.ndarray): 1-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: 1-dimensional numpy array.\n",
        "    \"\"\"\n",
        "    assert(len(x) == len(y))\n",
        "\n",
        "    result = np.zeros(len(x))\n",
        "    for i in range(len(x)):\n",
        "        result[i] = x[i]*y[i]\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ulXFBhZW2_n-"
      },
      "outputs": [],
      "source": [
        "def NUMPY_multiply(x, y):\n",
        "    \"\"\"\n",
        "    Multiply arguments element-wise.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 1-dimensional numpy array.\n",
        "    y (numpy.ndarray): 1-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: 1-dimensional numpy array.\n",
        "    \"\"\"\n",
        "\n",
        "    return x * y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "HkauisJ-YTfF"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_multiply(x, y):\n",
        "    \"\"\"\n",
        "    Multiply arguments element-wise.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 1-dimensional torch tensor.\n",
        "    y (torch.Tensor): 1-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: 1-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    return x * y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJamtDvL2_n_"
      },
      "source": [
        "**Test Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "M1WVGeFB2_n_",
        "outputId": "024d7470-950c-4a87-8408-4bc216567c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  59092 -201096 -282096 ...  129864  262353   80275]\n",
            "tensor([  59092, -201096, -282096,  ...,  129864,  262353,   80275])\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=3000)\n",
        "Y = np.random.randint(-1000, 1000, size=3000)\n",
        "\n",
        "print(NUMPY_multiply(X,Y))\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "Y = torch.from_numpy(Y)\n",
        "print(PYTORCH_multiply(X,Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUt8RkH22_oA"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> NUMPY_multiply(X,Y) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [&nbsp;&nbsp;59092&nbsp;-201096&nbsp;-282096&nbsp;...&nbsp;&nbsp;129864&nbsp;&nbsp;262353&nbsp;&nbsp;&nbsp;80275]\n",
        "        </tt></td>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_multiply(X,Y) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [&nbsp;&nbsp;59092&nbsp;-201096&nbsp;-282096&nbsp;...&nbsp;&nbsp;129864&nbsp;&nbsp;262353&nbsp;&nbsp;&nbsp;80275]\n",
        "        </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUntDGYM2_oB"
      },
      "source": [
        "#### **5.4. Sum-Product**\n",
        "In this task, you will implement the sum-product function for numpy arrays & torch tensors.\n",
        "\n",
        "The sum-product of vectors $\\textbf{x}$ and $\\textbf{y}$, each with n real component, is defined as\n",
        "\n",
        "$$\n",
        "f(\\textbf{x}, \\textbf{y}) =\n",
        "{\n",
        "\\begin{bmatrix}\n",
        "1\\\\\n",
        "1\\\\\n",
        "⋮\\\\\n",
        "1\n",
        "\\end{bmatrix}^{\\;T}\n",
        "%\n",
        "\\begin{bmatrix}\n",
        "x_1 y_1 & x_1 y_2 & … & x_1 y_n\\\\\n",
        "x_2 y_1 & x_2 y_2 & … & x_2 y_n\\\\\n",
        "⋮ & ⋮ & ⋱ & ⋮ \\\\\n",
        "x_m y_1 & x_m y_2 & … & x_m y_n\n",
        "\\end{bmatrix}\n",
        "%\n",
        "\\begin{bmatrix}\n",
        "1\\\\\n",
        "1\\\\\n",
        "⋮\\\\\n",
        "1\n",
        "\\end{bmatrix}\n",
        "} =\n",
        "\\displaystyle\\sum_{i=1}^{n} \\displaystyle\\sum_{j=1}^{n} x_i \\cdot y_j\n",
        "$$\n",
        "\n",
        "**Your Task**: Implement the functions `NUMPY_sumproduct` & `PYTORCH_sumproduct`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AU4_ZYWc2_oC"
      },
      "outputs": [],
      "source": [
        "def EXAMPLE_inefficient_sumproduct(x, y):\n",
        "    \"\"\"\n",
        "    Inefficiently sum over all the dimensions of the outer product\n",
        "    of two vectors.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 1-dimensional numpy array.\n",
        "    y (numpy.ndarray): 1-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy.int64: scalar quantity.\n",
        "    \"\"\"\n",
        "    assert(len(x) == len(y))\n",
        "\n",
        "    result = 0\n",
        "    for i in range(len(x)):\n",
        "        for j in range(len(y)):\n",
        "            result += x[i] * y[j]\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "-rxIQWnO2_oD"
      },
      "outputs": [],
      "source": [
        "def NUMPY_sumproduct(x, y):\n",
        "    \"\"\"\n",
        "    Sum over all the dimensions of the outer product of two vectors.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 1-dimensional numpy array.\n",
        "    y (numpy.ndarray): 1-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy.int64: scalar quantity.\n",
        "    \"\"\"\n",
        "    result = np.outer(x,y)\n",
        "    result = np.sum(result)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "PmP3En4dbg0D"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_sumproduct(x, y):\n",
        "    \"\"\"\n",
        "    Sum over all the dimensions of the outer product of two vectors.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 1-dimensional torch tensor.\n",
        "    y (torch.Tensor): 1-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.int64: scalar quantity.\n",
        "    \"\"\"\n",
        "    result = torch.outer(x,y)\n",
        "    result = torch.sum(result)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saWnHRYC2_oE"
      },
      "source": [
        "**Test Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "TM6MG6Lc2_oE",
        "outputId": "0e4d12ec-bc6e-4155-c118-68a9f911e960",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "265421520\n",
            "tensor(265421520)\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=3000)\n",
        "Y = np.random.randint(-1000, 1000, size=3000)\n",
        "\n",
        "print(NUMPY_sumproduct(X,Y))\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "Y = torch.from_numpy(Y)\n",
        "print(PYTORCH_sumproduct(X,Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVkFcF3U2_oF"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> NUMPY_sumproduct(X,Y) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt> 265421520 </tt></td>\n",
        "        <td style=\"text-align:left;\"><tt><b> TORCH_sumproduct(X,Y) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt> 265421520 </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrPg5BtP2_oG"
      },
      "source": [
        "#### **5.5. ReLU**\n",
        "\n",
        "In this task, you will implement the ReLU activation function for numpy arrays and torch tensors.\n",
        "\n",
        "The ReLU activation (also known as the rectifier or rectified linear unit)  function takes as input  a matrix $X = (x_{ij}$ and returns another metric $Z$ such that:\n",
        "\n",
        "$$Z = {\\tt ReLU}(X) \\implies \\begin{cases}z_{ij} = x_{ij}&{\\mbox{if }}x_{ij}>0\\\\z_{ij} = 0&{\\mbox{otherwise.}}\\end{cases}$$\n",
        "\n",
        "The notation $X = (x_{ij})$   indicates that $X$ is a 2D matrix whose elements are  $x_{ij}$.\n",
        "\n",
        "**Your Task:** Implement the functions `NUMPY_ReLU` & `PYTORCH_ReLU`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f7nUWF_2_oG"
      },
      "outputs": [],
      "source": [
        "def EXAMPLE_inefficient_ReLU(x):\n",
        "    \"\"\"\n",
        "    Inefficiently applies the rectified linear unit function\n",
        "    element-wise.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 2-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: 2-dimensional numpy array.\n",
        "    \"\"\"\n",
        "    result = np.copy(x)\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            if x[i][j] < 0:\n",
        "                result[i][j] = 0\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "6NcT2GhH2_oH"
      },
      "outputs": [],
      "source": [
        "def NUMPY_ReLU(x):\n",
        "    \"\"\"\n",
        "    Applies the rectified linear unit function element-wise.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 2-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: 2-dimensional numpy array.\n",
        "    \"\"\"\n",
        "\n",
        "    return np.maximum(x, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "dv8zksrxdRMx"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_ReLU(x):\n",
        "    \"\"\"\n",
        "    Applies the rectified linear unit function element-wise.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 2-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: 2-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    return torch.relu(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf6YHkuk2_oH"
      },
      "source": [
        "**Test Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "wX7cGu6l2_oH",
        "outputId": "2fe26cbe-3a5c-4320-e427-75f4f58ed552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0 653 ... 773 961   0]\n",
            " [  0 456   0 ... 168 273   0]\n",
            " [936 475   0 ... 408   0   0]\n",
            " ...\n",
            " [  0 396 457 ... 646   0   0]\n",
            " [645 943   0 ... 863   0 790]\n",
            " [641   0 379 ... 347   0   0]]\n",
            "tensor([[  0,   0, 653,  ..., 773, 961,   0],\n",
            "        [  0, 456,   0,  ..., 168, 273,   0],\n",
            "        [936, 475,   0,  ..., 408,   0,   0],\n",
            "        ...,\n",
            "        [  0, 396, 457,  ..., 646,   0,   0],\n",
            "        [645, 943,   0,  ..., 863,   0, 790],\n",
            "        [641,   0, 379,  ..., 347,   0,   0]])\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=(3000,3000))\n",
        "\n",
        "print(NUMPY_ReLU(X))\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "print(PYTORCH_ReLU(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04cIXq5Q2_oI"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> NUMPY_ReLU(X) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [[&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;653&nbsp;...&nbsp;773&nbsp;961&nbsp;&nbsp;&nbsp;0] <br>\n",
        "&nbsp;[&nbsp;&nbsp;0&nbsp;456&nbsp;&nbsp;&nbsp;0&nbsp;...&nbsp;168&nbsp;273&nbsp;&nbsp;&nbsp;0] <br>\n",
        "&nbsp;[936&nbsp;475&nbsp;&nbsp;&nbsp;0&nbsp;...&nbsp;408&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0] <br>\n",
        "&nbsp;... <br>\n",
        "&nbsp;[&nbsp;&nbsp;0&nbsp;396&nbsp;457&nbsp;...&nbsp;646&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0] <br>\n",
        "&nbsp;[645&nbsp;943&nbsp;&nbsp;&nbsp;0&nbsp;...&nbsp;863&nbsp;&nbsp;&nbsp;0&nbsp;790] <br>\n",
        "&nbsp;[641&nbsp;&nbsp;&nbsp;0&nbsp;379&nbsp;...&nbsp;347&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0]]\n",
        "        </tt></td>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_ReLU(X) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [[&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;653&nbsp;...&nbsp;773&nbsp;961&nbsp;&nbsp;&nbsp;0] <br>\n",
        "&nbsp;[&nbsp;&nbsp;0&nbsp;456&nbsp;&nbsp;&nbsp;0&nbsp;...&nbsp;168&nbsp;273&nbsp;&nbsp;&nbsp;0] <br>\n",
        "&nbsp;[936&nbsp;475&nbsp;&nbsp;&nbsp;0&nbsp;...&nbsp;408&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0] <br>\n",
        "&nbsp;... <br>\n",
        "&nbsp;[&nbsp;&nbsp;0&nbsp;396&nbsp;457&nbsp;...&nbsp;646&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0] <br>\n",
        "&nbsp;[645&nbsp;943&nbsp;&nbsp;&nbsp;0&nbsp;...&nbsp;863&nbsp;&nbsp;&nbsp;0&nbsp;790] <br>\n",
        "&nbsp;[641&nbsp;&nbsp;&nbsp;0&nbsp;379&nbsp;...&nbsp;347&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0]]\n",
        "        </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hpfecaX2_oJ"
      },
      "source": [
        "#### **5.6. Prime ReLU (derivative of ReLU)**\n",
        "\n",
        "In this task, you will implement the derivative of the ReLU activation function for numpy arrays and torch tensors.\n",
        "\n",
        "The derivative of the ReLU activation matrix $Z$ resulting from applying the derivative of the ReLU function to matrix $X$ is defined such that for $X,Z \\in M_{m \\times n} (\\mathbb{R})$,\n",
        "\n",
        "$$Z = {\\tt PrimeReLU}(X) \\implies \\begin{cases}z_{ij} = \\frac{d}{dx_{ij}} (x_{ij}) = 1&{\\mbox{if }}x_{ij}> 0\\\\z_{ij} = \\frac{d}{dx_{ij}} (0)=0&{\\mbox{otherwise.}}\\end{cases}$$\n",
        "\n",
        "\n",
        "**Your Task:** Implement the functions `NUMPY_PrimeReLU` & `PYTORCH_PrimeReLU`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OtY3Bwi2_oJ"
      },
      "outputs": [],
      "source": [
        "def EXAMPLE_inefficient_PrimeReLU(x):\n",
        "    \"\"\"\n",
        "    Inefficiently applies the derivative of the rectified linear unit\n",
        "    function element-wise.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 2-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: 2-dimensional numpy array.\n",
        "    \"\"\"\n",
        "\n",
        "    result = np.copy(x)\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            if x[i][j] <= 0:\n",
        "                result[i][j] = 0\n",
        "            else:\n",
        "                result[i][j] = 1\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "sB4gnatn2_oK"
      },
      "outputs": [],
      "source": [
        "def NUMPY_PrimeReLU(x):\n",
        "    \"\"\"\n",
        "    Applies the derivative of the rectified linear unit function\n",
        "    element-wise.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray): 2-dimensional numpy array.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: 2-dimensional numpy array.\n",
        "    \"\"\"\n",
        "\n",
        "    return np.where(x > 0, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "BJPbP09vpwHv"
      },
      "outputs": [],
      "source": [
        "def PYTORCH_PrimeReLU(x):\n",
        "    \"\"\"\n",
        "    Applies derivative of the rectified linear unit function\n",
        "    element-wise.\n",
        "\n",
        "    Parameters:\n",
        "    x (torch.Tensor): 2-dimensional torch tensor.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: 2-dimensional torch tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    return torch.where(x > 0, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS9ihFG92_oK"
      },
      "source": [
        "**Test Example:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "9pA_oCOL2_oL",
        "outputId": "74a31bdb-3abb-4beb-8fed-5ae701b71c2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 ... 1 1 0]\n",
            " [0 1 0 ... 1 1 0]\n",
            " [1 1 0 ... 1 0 0]\n",
            " ...\n",
            " [0 1 1 ... 1 0 0]\n",
            " [1 1 0 ... 1 0 1]\n",
            " [1 0 1 ... 1 0 0]]\n",
            "tensor([[0, 0, 1,  ..., 1, 1, 0],\n",
            "        [0, 1, 0,  ..., 1, 1, 0],\n",
            "        [1, 1, 0,  ..., 1, 0, 0],\n",
            "        ...,\n",
            "        [0, 1, 1,  ..., 1, 0, 0],\n",
            "        [1, 1, 0,  ..., 1, 0, 1],\n",
            "        [1, 0, 1,  ..., 1, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.randint(-1000, 1000, size=(3000,3000))\n",
        "\n",
        "print(NUMPY_PrimeReLU(X))\n",
        "\n",
        "X = torch.from_numpy(X)\n",
        "print(PYTORCH_PrimeReLU(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4Z_qYgM2_oL"
      },
      "source": [
        "**Expected Output**:\n",
        "<table style = \"align:40%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align:left;\"><tt><b> NUMPY_PrimeReLU(X) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [[0&nbsp;0&nbsp;1&nbsp;...&nbsp;1&nbsp;1&nbsp;0] <br>\n",
        "&nbsp;[0&nbsp;1&nbsp;0&nbsp;...&nbsp;1&nbsp;1&nbsp;0] <br>\n",
        "&nbsp;[1&nbsp;1&nbsp;0&nbsp;...&nbsp;1&nbsp;0&nbsp;0] <br>\n",
        "&nbsp;... <br>\n",
        "&nbsp;[0&nbsp;1&nbsp;1&nbsp;...&nbsp;1&nbsp;0&nbsp;0] <br>\n",
        "&nbsp;[1&nbsp;1&nbsp;0&nbsp;...&nbsp;1&nbsp;0&nbsp;1] <br>\n",
        "&nbsp;[1&nbsp;0&nbsp;1&nbsp;...&nbsp;1&nbsp;0&nbsp;0]]\n",
        "        </tt></td>\n",
        "        <td style=\"text-align:left;\"><tt><b> PYTORCH_PrimeReLU(X) </b></tt></td>\n",
        "        <td style=\"text-align:left;\"><tt>\n",
        "            [[0&nbsp;0&nbsp;1&nbsp;...&nbsp;1&nbsp;1&nbsp;0] <br>\n",
        "&nbsp;[0&nbsp;1&nbsp;0&nbsp;...&nbsp;1&nbsp;1&nbsp;0] <br>\n",
        "&nbsp;[1&nbsp;1&nbsp;0&nbsp;...&nbsp;1&nbsp;0&nbsp;0] <br>\n",
        "&nbsp;... <br>\n",
        "&nbsp;[0&nbsp;1&nbsp;1&nbsp;...&nbsp;1&nbsp;0&nbsp;0] <br>\n",
        "&nbsp;[1&nbsp;1&nbsp;0&nbsp;...&nbsp;1&nbsp;0&nbsp;1] <br>\n",
        "&nbsp;[1&nbsp;0&nbsp;1&nbsp;...&nbsp;1&nbsp;0&nbsp;0]]\n",
        "        </tt></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "dXm9FUllFSSw",
        "wUntDGYM2_oB"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}