{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purpleiron/MySchoolProjects/blob/main/ICT303_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mKK4Rd8vhPS"
      },
      "source": [
        "#  **ICT303 - Assignment 1**\n",
        "\n",
        "**Your name: <enter here your full name>**\n",
        "\n",
        "**Student ID: <enter here your student ID>**\n",
        "\n",
        "**Email: <enter here your email address>**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Description**\n",
        "\n",
        "We would like to develop, using Multilayer Perceptron (MLP), a computer program that takes images of handwritten text, finds the written characters in the image and displays the written characters.\n",
        "\n",
        "To achieve this, we will proceed in steps:\n",
        "\n",
        "1. Develop and train an MLP for the recognition of handwritten characters from images. In the first instance, the images are assumed to contain only one handwritten.\n",
        "2. Train and test the MLP, and evaluate its performance by using loss curves and proper accuracy/performance measures\n",
        "3. Improve the performance of the MLP by tuning its hyper parameters.\n",
        "4. Extend the program you developed to localize (detect) and recognize handwritten characters in an image that contains multiple handwritten characters.\n",
        "\n",
        "For this purpose, we will use the following dataset for training, validation and testing: https://www.kaggle.com/datasets/dhruvildave/english-handwritten-characters-dataset.\n",
        "\n",
        "You are required to justify every design choice. Justifications should be theoretical and validated with experiments.\n",
        "\n",
        "It is important that you start as earlier as possible. Coding is usually easy. However, training neural networks and tuning its hyper-parameters takes time."
      ],
      "metadata": {
        "id": "by2yigAYoub0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2. Marking Guide**##\n",
        "\n",
        "- The overal structure of the program - it should follow the structure we used so far in the labs **[30 Marks]**. This includes:\n",
        "  - A class that defines the network architecture that extends the class `nn.Module`. It should have a constructor method (`__init__()`) and a forward function (`forward()`)\n",
        "  - The Trainer class\n",
        "  - A main function\n",
        "\n",
        "- Training working and running on GPU **[10 marks]**\n",
        "\n",
        "- Curves for training loss and validation loss plotted and training stopped when the network starts to overfit (i.e., when the validation loss starts to increase). You must use TensorBoard to visualize curves and monitor performance **[10 marks]**\n",
        "\n",
        "- Testing code properly working. **[10 marks]**\n",
        "\n",
        "- Hyper parameters finetuned and the best ones selected. **[10 marks]**\n",
        "\n",
        "- Quality of the dicussions **[20 marks]**: did the student discuss various design choices, including the hyperparamters or any choices they made to improve the performance? Any design choice should be properly justified.\n",
        "\n",
        "- Extension to the localization of the characters **[10 marks]**"
      ],
      "metadata": {
        "id": "y9y_vBKmcS3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. What to submit**\n",
        "\n",
        "You need to upload to LMS the notebook as well as a folder that contains the .py files you created. All classes should be implemented in .py files. The notebook will sever as a documentation of your work as well as the codes that demonstrated the training, validation and testing of your MLP models that you created.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uPY9Ha_3qs68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import necessary dependencies"
      ],
      "metadata": {
        "id": "4vbqvhnze2PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "#print('CUDA available:', torch.cuda.is_available())\n",
        "#print('GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "with zipfile.ZipFile(\"/content/drive/My Drive/archive.zip\", 'r') as zip_ref:\n",
        "  zip_ref.extractall(\"/content/dataset_folder\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhHTX_hClY0P",
        "outputId": "1dd53895-c86c-4307-b85d-da202bde8564"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Transformation/preprocessing\n",
        "\n",
        "I took a look at the images in the dataset and they were black and white. This should allow me to convert the images to greyscale and save on training time. I'm not sure how good it will be if the test images will not be in grayscale, but I can make the test images grayscale as well. If you want to transform the images to a different resolution, just change the parameters in transforms.Resize()"
      ],
      "metadata": {
        "id": "qJi7qAWlldy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Dataset"
      ],
      "metadata": {
        "id": "wBm-vbZPn5Kn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the model\n",
        "\n"
      ],
      "metadata": {
        "id": "iCSdouf-4KAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size=224*224, output_size=62, lr=0.001):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        # The output size is 62, which might correspond to the number of classes you have (10 digits + 52 letters).\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "\n",
        "            nn.Flatten(),\n",
        "\n",
        "            nn.Linear(input_size, 512),\n",
        "            # Justification: The first hidden layer has 512 neurons. This number is chosen to provide a\n",
        "            # good balance between model complexity and computational efficiency.\n",
        "\n",
        "            nn.ReLU(),\n",
        "            # Justification: ReLU is used as the activation function because it helps with faster convergence\n",
        "            # and alleviates the vanishing gradient problem compared to sigmoid or tanh.\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            # Justification: A second hidden layer with 256 neurons is used to increase the model's ability to\n",
        "            # capture non-linear relationships in the data.\n",
        "\n",
        "            nn.ReLU(),\n",
        "            # Justification: Another ReLU for non-linear activation.\n",
        "\n",
        "            nn.Linear(256, output_size),\n",
        "            # Justification: The output layer size corresponds to the number of classes.\n",
        "\n",
        "            nn.LogSoftmax(dim=1)\n",
        "            # Justification: LogSoftmax is used in the output layer to obtain log-probabilities which are more\n",
        "            # numerically stable for the subsequent calculation of the negative log likelihood loss during training.\n",
        "\n",
        "\n",
        "        )\n",
        "\n",
        "        self.lr = lr\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), self.lr)\n",
        "        # Justification: The Adam optimizer is used as it combines the best properties of the AdaGrad and RMSProp\n",
        "        # algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems.\n",
        "\n",
        "    def loss(self, y_hat, y):\n",
        "        fn = nn.NLLLoss()\n",
        "        return fn(y_hat, y)\n",
        "        # Justification: NLLLoss (Negative Log Likelihood Loss) is used as the loss function for multi-class\n",
        "        # classification problems when combined with LogSoftmax in the output layer. It is efficient and\n",
        "        # calculates the loss between the predicted log-probabilities and the ground truth labels.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JjMRmuW5-GNS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Trainer class"
      ],
      "metadata": {
        "id": "cT3s4HqBCA4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, criterion, train_loader, val_loader=None, num_epochs=25, patience=5, device='cuda'):\n",
        "        \"\"\"\n",
        "        Initialize the Trainer with model, optimizer, criterion, data loaders, and training configurations.\n",
        "        \"\"\"\n",
        "        # Justification for changes:\n",
        "        # - Added model, optimizer, criterion as parameters for flexibility and explicitness.\n",
        "        # - Included train_loader and val_loader for separate training and validation data handling.\n",
        "        # - Added device parameter for flexibility between CPU and GPU training.\n",
        "        self.model = model.to(device)\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.num_epochs = num_epochs\n",
        "        self.patience = patience\n",
        "        self.device = device\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.patience_counter = 0\n",
        "        self.writer = SummaryWriter()  # Default log_dir is fine; no need to customize without specific requirement.\n",
        "\n",
        "    def train_epoch(self):\n",
        "        \"\"\"\n",
        "        Train the model for one epoch.\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in tqdm(self.train_loader, desc=\"Training\"):\n",
        "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        average_loss = running_loss / len(self.train_loader)\n",
        "        self.writer.add_scalar('train_loss', average_loss)\n",
        "        return average_loss\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"\n",
        "        Validate the model on the validation dataset.\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in tqdm(self.val_loader, desc=\"Validation\"):\n",
        "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "        average_val_loss = val_loss / len(self.val_loader)\n",
        "        self.writer.add_scalar('val_loss', average_val_loss)\n",
        "        return average_val_loss\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"\n",
        "        Fit the model to the data.\n",
        "        \"\"\"\n",
        "        for epoch in range(self.num_epochs):\n",
        "            train_loss = self.train_epoch()\n",
        "            print(f'Epoch {epoch+1}/{self.num_epochs}, Train Loss: {train_loss:.4f}')\n",
        "\n",
        "            if self.val_loader:\n",
        "                val_loss = self.validate()\n",
        "                print(f'Epoch {epoch+1}/{self.num_epochs}, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "                if val_loss < self.best_val_loss:\n",
        "                    self.best_val_loss = val_loss\n",
        "                    self.patience_counter = 0\n",
        "                else:\n",
        "                    self.patience_counter += 1\n",
        "                    if self.patience_counter >= self.patience:\n",
        "                        print('Early stopping triggered')\n",
        "                        break\n",
        "        self.writer.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "J5-RVkF0CFCz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main function"
      ],
      "metadata": {
        "id": "Fs-Zd6MVDqyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "# Your MLP and Trainer classes would be defined here...\n",
        "\n",
        "def main():\n",
        "    # Data loading and transformation\n",
        "    dataset_path = '/content/dataset_folder/archive/Img/'\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Create the dataset using the ImageFolder wrapper\n",
        "    dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "    # Map indices to actual class labels\n",
        "    idx_to_class = {i: cls for cls, i in dataset.class_to_idx.items()}\n",
        "\n",
        "    # Define the actual classes in order\n",
        "    actual_classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                      'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
        "                      'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "\n",
        "    # Map the folder indices to actual class labels\n",
        "    folder_idx_to_label = {idx: label for idx, label in enumerate(actual_classes)}\n",
        "\n",
        "    # Splitting dataset into training, validation, and test sets\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.15 * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "    # Model initialization\n",
        "    model = MLP(input_size=224*224, output_size=62, lr=0.003)\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Trainer initialization and training\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        num_epochs=25,\n",
        "        patience=5,\n",
        "        device='cuda'\n",
        "    )\n",
        "    trainer.fit()\n",
        "\n",
        "    # Test the model\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_predictions, test_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "            inputs = inputs.to('cuda')\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_predictions.extend(predicted.view(-1).tolist())\n",
        "            test_labels.extend(labels.view(-1).tolist())\n",
        "\n",
        "    # Calculate the accuracy\n",
        "    accuracy = accuracy_score(test_labels, test_predictions)\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Optionally, print out a few predictions\n",
        "    for i in range(10):\n",
        "        print(f\"True label: {folder_idx_to_label[test_labels[i]]}, Predicted label: {folder_idx_to_label[test_predictions[i]]}\")\n"
      ],
      "metadata": {
        "id": "crlXPkAyEHS-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running"
      ],
      "metadata": {
        "id": "IvZqTsuNEXUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "denKq0aAEZka",
        "outputId": "c7e89e97-4f45-4975-cbf1-f537f6816822"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25, Train Loss: 7.3398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25, Validation Loss: 4.2296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/25, Train Loss: 4.1507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/25, Validation Loss: 4.1157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/25, Train Loss: 4.1202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/25, Validation Loss: 4.1253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/25, Train Loss: 4.1133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/25, Validation Loss: 4.1359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/25, Train Loss: 4.1178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/25, Validation Loss: 4.1221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/25, Train Loss: 4.1093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/25, Validation Loss: 4.1197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/25, Train Loss: 4.1082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/25, Validation Loss: 4.1089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/25, Train Loss: 4.1089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/25, Validation Loss: 4.1131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:36<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/25, Train Loss: 4.0958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/25, Validation Loss: 4.1130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/25, Train Loss: 4.0435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/25, Validation Loss: 4.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/25, Train Loss: 3.9772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/25, Validation Loss: 4.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/25, Train Loss: 3.9166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/25, Validation Loss: 4.0524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/25, Train Loss: 3.8353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/25, Validation Loss: 3.7611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/25, Train Loss: 3.7217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/25, Validation Loss: 3.6748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/25, Train Loss: 3.6518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/25, Validation Loss: 3.4618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/25, Train Loss: 3.4461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/25, Validation Loss: 3.3203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/25, Train Loss: 3.3810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/25, Validation Loss: 3.3261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/25, Train Loss: 3.3177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/25, Validation Loss: 3.1893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/25, Train Loss: 3.2198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/25, Validation Loss: 3.2495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/25, Train Loss: 3.1197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/25, Validation Loss: 3.1028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/25, Train Loss: 3.0152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/25, Validation Loss: 3.0579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/25, Train Loss: 2.9061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/25, Validation Loss: 2.9536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:35<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/25, Train Loss: 2.8616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/25, Validation Loss: 3.0566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/25, Train Loss: 2.7837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/25, Validation Loss: 3.0775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/25, Train Loss: 2.7174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/25, Validation Loss: 2.8468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 8/8 [00:06<00:00,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.2812\n",
            "True label: O, Predicted label: O\n",
            "True label: W, Predicted label: W\n",
            "True label: y, Predicted label: c\n",
            "True label: W, Predicted label: U\n",
            "True label: 3, Predicted label: J\n",
            "True label: t, Predicted label: b\n",
            "True label: b, Predicted label: U\n",
            "True label: r, Predicted label: N\n",
            "True label: o, Predicted label: Y\n",
            "True label: D, Predicted label: V\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "# Your MLP and Trainer classes would be defined here...\n",
        "\n",
        "def main():\n",
        "    # Data loading and transformation\n",
        "    dataset_path = '/content/dataset_folder/archive/Img/'\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Create the dataset using the ImageFolder wrapper\n",
        "    dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "    # Map indices to actual class labels\n",
        "    idx_to_class = {i: cls for cls, i in dataset.class_to_idx.items()}\n",
        "\n",
        "    # Define the actual classes in order\n",
        "    actual_classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                      'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
        "                      'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "\n",
        "    # Map the folder indices to actual class labels\n",
        "    folder_idx_to_label = {idx: label for idx, label in enumerate(actual_classes)}\n",
        "\n",
        "    # Splitting dataset into training, validation, and test sets\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.15 * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "    # Model initialization\n",
        "    model = MLP(input_size=224*224*3, output_size=62, lr=0.001)\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Trainer initialization and training\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        num_epochs=25,\n",
        "        patience=5,\n",
        "        device='cuda'\n",
        "    )\n",
        "    trainer.fit()\n",
        "\n",
        "    # Test the model\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_predictions, test_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "            inputs = inputs.to('cuda')\n",
        "            labels = labels.to('cuda')\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_predictions.extend(predicted.view(-1).tolist())\n",
        "            test_labels.extend(labels.view(-1).tolist())\n",
        "\n",
        "    # Calculate the accuracy\n",
        "    accuracy = accuracy_score(test_labels, test_predictions)\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Optionally, print out a few predictions\n",
        "    for i in range(10):\n",
        "        print(f\"True label: {folder_idx_to_label[test_labels[i]]}, Predicted label: {folder_idx_to_label[test_predictions[i]]}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "VGJUDg9V1QaI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#First test\n",
        "This is using 224x224x3. It seems pretty bad, I'm gonna try to preprocess the photos to be grayscale so that there would be 3 times lesser inputs first\n",
        "\n",
        "\n",
        "```\n",
        "Training: 100%|██████████| 38/38 [00:43<00:00,  1.13s/it]\n",
        "Epoch 1/25, Train Loss: 22.8603\n",
        "Validation: 100%|██████████| 8/8 [00:09<00:00,  1.16s/it]\n",
        "Epoch 1/25, Validation Loss: 4.6418\n",
        "Training: 100%|██████████| 38/38 [00:43<00:00,  1.14s/it]\n",
        "Epoch 2/25, Train Loss: 4.2615\n",
        "Validation: 100%|██████████| 8/8 [00:09<00:00,  1.16s/it]\n",
        "Epoch 2/25, Validation Loss: 4.1615\n",
        "Training: 100%|██████████| 38/38 [00:43<00:00,  1.13s/it]\n",
        "Epoch 3/25, Train Loss: 4.1377\n",
        "Validation: 100%|██████████| 8/8 [00:09<00:00,  1.18s/it]\n",
        "Epoch 3/25, Validation Loss: 4.1130\n",
        "Training: 100%|██████████| 38/38 [00:44<00:00,  1.17s/it]\n",
        "Epoch 4/25, Train Loss: 4.1241\n",
        "Validation: 100%|██████████| 8/8 [00:09<00:00,  1.18s/it]\n",
        "Epoch 4/25, Validation Loss: 4.1286\n",
        "Training: 100%|██████████| 38/38 [00:43<00:00,  1.14s/it]\n",
        "Epoch 5/25, Train Loss: 4.1279\n",
        "Validation: 100%|██████████| 8/8 [00:09<00:00,  1.18s/it]\n",
        "Epoch 5/25, Validation Loss: 4.1297\n",
        "Training: 100%|██████████| 38/38 [00:43<00:00,  1.15s/it]\n",
        "Epoch 6/25, Train Loss: 4.1275\n",
        "Validation: 100%|██████████| 8/8 [00:09<00:00,  1.13s/it]\n",
        "Epoch 6/25, Validation Loss: 4.1305\n",
        "Training: 100%|██████████| 38/38 [00:43<00:00,  1.16s/it]\n",
        "Epoch 7/25, Train Loss: 4.1270\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.10s/it]\n",
        "Epoch 7/25, Validation Loss: 4.1313\n",
        "Training: 100%|██████████| 38/38 [00:44<00:00,  1.17s/it]\n",
        "Epoch 8/25, Train Loss: 4.1268\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.05s/it]\n",
        "Epoch 8/25, Validation Loss: 4.1323\n",
        "Early stopping triggered\n",
        "Testing: 100%|██████████| 8/8 [00:09<00:00,  1.18s/it]Test Accuracy: 0.0117\n",
        "True label: 2, Predicted label: c\n",
        "True label: P, Predicted label: c\n",
        "True label: s, Predicted label: c\n",
        "True label: E, Predicted label: c\n",
        "True label: U, Predicted label: c\n",
        "True label: o, Predicted label: c\n",
        "True label: 6, Predicted label: c\n",
        "True label: t, Predicted label: c\n",
        "True label: Q, Predicted label: c\n",
        "True label: 8, Predicted label: c\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "cvqQYxVC-dcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Second try\n",
        "I changed it to grayscale to see if it would be better or be faster but I don't think it did much. For some reason, both time the model predicted the same thing the whole time\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Training: 100%|██████████| 38/38 [00:43<00:00,  1.15s/it]\n",
        "Epoch 1/25, Train Loss: 35.9448\n",
        "Validation: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n",
        "Epoch 1/25, Validation Loss: 5.5344\n",
        "Training: 100%|██████████| 38/38 [00:43<00:00,  1.14s/it]\n",
        "Epoch 2/25, Train Loss: 4.2988\n",
        "Validation: 100%|██████████| 8/8 [00:09<00:00,  1.18s/it]\n",
        "Epoch 2/25, Validation Loss: 4.1325\n",
        "Training: 100%|██████████| 38/38 [00:43<00:00,  1.14s/it]\n",
        "Epoch 3/25, Train Loss: 4.1148\n",
        "Validation: 100%|██████████| 8/8 [00:09<00:00,  1.22s/it]\n",
        "Epoch 3/25, Validation Loss: 4.1123\n",
        "Training: 100%|██████████| 38/38 [00:43<00:00,  1.15s/it]\n",
        "Epoch 4/25, Train Loss: 4.1165\n",
        "Validation: 100%|██████████| 8/8 [00:09<00:00,  1.19s/it]\n",
        "Epoch 4/25, Validation Loss: 4.1284\n",
        "Training: 100%|██████████| 38/38 [00:43<00:00,  1.16s/it]\n",
        "Epoch 5/25, Train Loss: 4.1276\n",
        "Validation: 100%|██████████| 8/8 [00:09<00:00,  1.20s/it]\n",
        "Epoch 5/25, Validation Loss: 4.1291\n",
        "Training: 100%|██████████| 38/38 [00:44<00:00,  1.17s/it]\n",
        "Epoch 6/25, Train Loss: 4.1272\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.07s/it]\n",
        "Epoch 6/25, Validation Loss: 4.1302\n",
        "Training: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it]\n",
        "Epoch 7/25, Train Loss: 4.1266\n",
        "Validation: 100%|██████████| 8/8 [00:10<00:00,  1.35s/it]\n",
        "Epoch 7/25, Validation Loss: 4.1312\n",
        "Training: 100%|██████████| 38/38 [00:56<00:00,  1.48s/it]\n",
        "Epoch 8/25, Train Loss: 4.1265\n",
        "Validation: 100%|██████████| 8/8 [00:11<00:00,  1.47s/it]\n",
        "Epoch 8/25, Validation Loss: 4.1321\n",
        "Early stopping triggered\n",
        "Testing: 100%|██████████| 8/8 [00:09<00:00,  1.23s/it]Test Accuracy: 0.0059\n",
        "True label: V, Predicted label: 6\n",
        "True label: 8, Predicted label: 6\n",
        "True label: K, Predicted label: 6\n",
        "True label: u, Predicted label: 6\n",
        "True label: o, Predicted label: 6\n",
        "True label: X, Predicted label: 6\n",
        "True label: 1, Predicted label: 6\n",
        "True label: D, Predicted label: 6\n",
        "True label: 9, Predicted label: 6\n",
        "True label: 8, Predicted label: 6\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "XLItc5BXCMGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Third try\n",
        "Seems like I didn't do the grayscale properly, so now I added\n",
        "\n",
        "```\n",
        "transforms.Grayscale(),\n",
        "```\n",
        "to the transform part of the main function. Then I tried again:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.03it/s]\n",
        "Epoch 1/25, Train Loss: 8.7023\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.11it/s]\n",
        "Epoch 1/25, Validation Loss: 4.2525\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n",
        "Epoch 2/25, Train Loss: 4.1504\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.08s/it]\n",
        "Epoch 2/25, Validation Loss: 4.1328\n",
        "Training: 100%|██████████| 38/38 [00:46<00:00,  1.21s/it]\n",
        "Epoch 3/25, Train Loss: 4.0829\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.12s/it]\n",
        "Epoch 3/25, Validation Loss: 4.1511\n",
        "Training: 100%|██████████| 38/38 [00:43<00:00,  1.14s/it]\n",
        "Epoch 4/25, Train Loss: 3.9323\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.05it/s]\n",
        "Epoch 4/25, Validation Loss: 3.9317\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n",
        "Epoch 5/25, Train Loss: 3.7808\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n",
        "Epoch 5/25, Validation Loss: 3.8885\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n",
        "Epoch 6/25, Train Loss: 3.6409\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.11it/s]\n",
        "Epoch 6/25, Validation Loss: 3.9240\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.03it/s]\n",
        "Epoch 7/25, Train Loss: 3.4636\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n",
        "Epoch 7/25, Validation Loss: 3.5234\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n",
        "Epoch 8/25, Train Loss: 3.3190\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.02it/s]\n",
        "Epoch 8/25, Validation Loss: 3.5741\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n",
        "Epoch 9/25, Train Loss: 3.1756\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.08it/s]\n",
        "Epoch 9/25, Validation Loss: 3.5298\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n",
        "Epoch 10/25, Train Loss: 3.0995\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n",
        "Epoch 10/25, Validation Loss: 3.2305\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.03it/s]\n",
        "Epoch 11/25, Train Loss: 2.9847\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.12it/s]\n",
        "Epoch 11/25, Validation Loss: 3.4461\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n",
        "Epoch 12/25, Train Loss: 2.8964\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.01s/it]\n",
        "Epoch 12/25, Validation Loss: 3.7214\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 13/25, Train Loss: 2.8732\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.01s/it]\n",
        "Epoch 13/25, Validation Loss: 3.0940\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n",
        "Epoch 14/25, Train Loss: 2.6759\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.11it/s]\n",
        "Epoch 14/25, Validation Loss: 3.2202\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.03it/s]\n",
        "Epoch 15/25, Train Loss: 2.6783\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.02s/it]\n",
        "Epoch 15/25, Validation Loss: 3.0593\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 16/25, Train Loss: 2.5362\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.04it/s]\n",
        "Epoch 16/25, Validation Loss: 2.9889\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n",
        "Epoch 17/25, Train Loss: 2.4245\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.12it/s]\n",
        "Epoch 17/25, Validation Loss: 2.8331\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n",
        "Epoch 18/25, Train Loss: 2.4480\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.00it/s]\n",
        "Epoch 18/25, Validation Loss: 2.8302\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.07it/s]\n",
        "Epoch 19/25, Train Loss: 2.2620\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.05it/s]\n",
        "Epoch 19/25, Validation Loss: 2.8571\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 20/25, Train Loss: 2.2319\n",
        "Validation: 100%|██████████| 8/8 [00:06<00:00,  1.15it/s]\n",
        "Epoch 20/25, Validation Loss: 2.9226\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 21/25, Train Loss: 2.0822\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n",
        "Epoch 21/25, Validation Loss: 2.8602\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.08it/s]\n",
        "Epoch 22/25, Train Loss: 2.0601\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.03it/s]\n",
        "Epoch 22/25, Validation Loss: 2.7978\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n",
        "Epoch 23/25, Train Loss: 2.0359\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.14it/s]\n",
        "Epoch 23/25, Validation Loss: 2.8043\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 24/25, Train Loss: 1.9455\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.00it/s]\n",
        "Epoch 24/25, Validation Loss: 2.6880\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.08it/s]\n",
        "Epoch 25/25, Train Loss: 2.0011\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n",
        "Epoch 25/25, Validation Loss: 2.7536\n",
        "Testing: 100%|██████████| 8/8 [00:07<00:00,  1.03it/s]Test Accuracy: 0.3613\n",
        "True label: v, Predicted label: v\n",
        "True label: r, Predicted label: r\n",
        "True label: D, Predicted label: D\n",
        "True label: A, Predicted label: a\n",
        "True label: G, Predicted label: G\n",
        "True label: j, Predicted label: j\n",
        "True label: z, Predicted label: y\n",
        "True label: l, Predicted label: l\n",
        "True label: e, Predicted label: y\n",
        "True label: 3, Predicted label: X\n",
        "\n",
        "```\n",
        "\n",
        "This time it was much better, it was able to finish training without stopping early and the accuracy was much better than the previous times. I think I might change the learning rate next.\n"
      ],
      "metadata": {
        "id": "O7cgtUx-DWIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fourth try\n",
        "\n",
        "I changed the learning rate to 0.03. It was still able to finish without early stopping, but did not perform better than the one with 0.001 learning rate\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.07it/s]\n",
        "Epoch 1/25, Train Loss: 7.3398\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.02it/s]\n",
        "Epoch 1/25, Validation Loss: 4.2296\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 2/25, Train Loss: 4.1507\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.14it/s]\n",
        "Epoch 2/25, Validation Loss: 4.1157\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n",
        "Epoch 3/25, Train Loss: 4.1202\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.05it/s]\n",
        "Epoch 3/25, Validation Loss: 4.1253\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.08it/s]\n",
        "Epoch 4/25, Train Loss: 4.1133\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.00s/it]\n",
        "Epoch 4/25, Validation Loss: 4.1359\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 5/25, Train Loss: 4.1178\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.09it/s]\n",
        "Epoch 5/25, Validation Loss: 4.1221\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 6/25, Train Loss: 4.1093\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.09it/s]\n",
        "Epoch 6/25, Validation Loss: 4.1197\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 7/25, Train Loss: 4.1082\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.00it/s]\n",
        "Epoch 7/25, Validation Loss: 4.1089\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n",
        "Epoch 8/25, Train Loss: 4.1089\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.14it/s]\n",
        "Epoch 8/25, Validation Loss: 4.1131\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.03it/s]\n",
        "Epoch 9/25, Train Loss: 4.0958\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.04it/s]\n",
        "Epoch 9/25, Validation Loss: 4.1130\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 10/25, Train Loss: 4.0435\n",
        "Validation: 100%|██████████| 8/8 [00:08<00:00,  1.00s/it]\n",
        "Epoch 10/25, Validation Loss: 4.0844\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n",
        "Epoch 11/25, Train Loss: 3.9772\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.13it/s]\n",
        "Epoch 11/25, Validation Loss: 4.0009\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n",
        "Epoch 12/25, Train Loss: 3.9166\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.05it/s]\n",
        "Epoch 12/25, Validation Loss: 4.0524\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.07it/s]\n",
        "Epoch 13/25, Train Loss: 3.8353\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n",
        "Epoch 13/25, Validation Loss: 3.7611\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 14/25, Train Loss: 3.7217\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.12it/s]\n",
        "Epoch 14/25, Validation Loss: 3.6748\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 15/25, Train Loss: 3.6518\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.10it/s]\n",
        "Epoch 15/25, Validation Loss: 3.4618\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.07it/s]\n",
        "Epoch 16/25, Train Loss: 3.4461\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n",
        "Epoch 16/25, Validation Loss: 3.3203\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n",
        "Epoch 17/25, Train Loss: 3.3810\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.11it/s]\n",
        "Epoch 17/25, Validation Loss: 3.3261\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n",
        "Epoch 18/25, Train Loss: 3.3177\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.09it/s]\n",
        "Epoch 18/25, Validation Loss: 3.1893\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 19/25, Train Loss: 3.2198\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n",
        "Epoch 19/25, Validation Loss: 3.2495\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.07it/s]\n",
        "Epoch 20/25, Train Loss: 3.1197\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.09it/s]\n",
        "Epoch 20/25, Validation Loss: 3.1028\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 21/25, Train Loss: 3.0152\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.13it/s]\n",
        "Epoch 21/25, Validation Loss: 3.0579\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.06it/s]\n",
        "Epoch 22/25, Train Loss: 2.9061\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.02it/s]\n",
        "Epoch 22/25, Validation Loss: 2.9536\n",
        "Training: 100%|██████████| 38/38 [00:35<00:00,  1.07it/s]\n",
        "Epoch 23/25, Train Loss: 2.8616\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.06it/s]\n",
        "Epoch 23/25, Validation Loss: 3.0566\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n",
        "Epoch 24/25, Train Loss: 2.7837\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.09it/s]\n",
        "Epoch 24/25, Validation Loss: 3.0775\n",
        "Training: 100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n",
        "Epoch 25/25, Train Loss: 2.7174\n",
        "Validation: 100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n",
        "Epoch 25/25, Validation Loss: 2.8468\n",
        "Testing: 100%|██████████| 8/8 [00:06<00:00,  1.15it/s]Test Accuracy: 0.2812\n",
        "True label: O, Predicted label: O\n",
        "True label: W, Predicted label: W\n",
        "True label: y, Predicted label: c\n",
        "True label: W, Predicted label: U\n",
        "True label: 3, Predicted label: J\n",
        "True label: t, Predicted label: b\n",
        "True label: b, Predicted label: U\n",
        "True label: r, Predicted label: N\n",
        "True label: o, Predicted label: Y\n",
        "True label: D, Predicted label: V\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "_Thdsze1Htdg"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}